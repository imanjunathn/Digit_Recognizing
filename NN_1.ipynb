{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjQptK0HOrSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-IIOxeuSyU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a517e45c-0771-4dc2-9032-aff81814527e"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Activation,BatchNormalization, Dropout\n",
        "from tensorflow.keras import optimizers,regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMt52HZ1TH7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mainPath = '/content/gdrive/My Drive/AIML/SVHN_image_clf/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6UF-_qTTAde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(fileName):\n",
        "  data = h5py.File(mainPath+fileName,'r')\n",
        "  print(list(data.keys()))\n",
        "  X_train = data['X_train'][:]\n",
        "  y_train = data['y_train'][:]\n",
        "  X_test = data['X_test'][:]\n",
        "  y_test = data['y_test'][:]\n",
        "  X_val = data['X_val'][:]\n",
        "  y_val = data['y_val'][:]\n",
        "  data.close()\n",
        "  return (X_train,X_test,y_train,y_test,X_val,y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5X89J9sTfHb",
        "colab_type": "code",
        "outputId": "d487e6f0-1a60-450e-d3fd-1ade0d8946cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train,X_test,y_train,y_test,X_val,y_val = loadData('SVHN_single_grey.h5')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERqQbs98905W",
        "colab_type": "code",
        "outputId": "d8436d3c-f069-4573-85ef-1a0e7f31c69f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "# Let's visualize the data\n",
        "print(f\"Label {y_train[18000]}\")\n",
        "plt.imshow(X_train[18000],cmap='gray')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f47731ba5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAY0klEQVR4nO2da2xd1ZXH/8shTtIkJHHiGCdx8waSIkqIC0lbVUyrlkxViSKNEHxAfEBNNSrSVOp8QIw0ZaT50I6mrfqJUTqg0lGnFEor0AgNMKgCKrUpCSROyMtJ6jyM8yBPk7edNR/uiepEZ/3v9fG95wb2/ydZvt7r7nPW3ecsn3P2/661zd0hhPjk09JsB4QQ5aBgFyIRFOxCJIKCXYhEULALkQgKdiES4YaxdDazNQB+CmAcgP909x+w97e0tPgNN4xpl1fBZEMzq9t+rtDSMvr/jY3wo8g2i45VUWk26se21wgZeNy4cXXdV9HjWZbEfenSJQwPD+c6aWP40OMA7ALwVQAHAbwD4CF33xb1aW1t9fb29lxbkZPx4sWLYZ/W1tbQxmAHc9KkSaPeHvvnxv55XL58ObQV+Wxse0X9YLYLFy7ktg8NDRXa3vDwcGhj3HjjjaP2g1H0eLJztcj2orE6cOAAzp8/n3sSj+U2/i4Au919r7tfBPAcgPvGsD0hRAMZS7DPBXBgxN8HszYhxHVI/R6gA8xsLYC1QPz8JIRoPGO5svcD6Brx97ys7SrcfZ27d7t7d5EJLiFEfRhL9L0DYKmZLTSzVgAPAni5Pm4JIepN4dt4dx8ys8cAvIqK9PaMu79frV80281mOaOZ0wkTJjD/Qtv48eNDW71lrUbAZq2LUHQ2vsidWiPkUuZHdO4UlQDZeLB+TEGJtskUgyLn3Jie2d39FQCvjGUbQohy0EO0EImgYBciERTsQiSCgl2IRFCwC5EIDf8G3bVE8gqTXSJppd4SFFBMkin6zcCi/jOpKbIxGaeojRElDTGJ9dy5c6GNnR9FsvZYH+YjS8hh586ZM2dC25QpU3LbZ8+eHfaJxvfIkSNhH13ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEKHU23t3D8jxsRpslvJRJ5CNLrLl06VJoY7PqbGaXlTiKttmI8lisX5HSWWymm40j8zHq14h0a+b/tGnTQtvSpUtz21euXBn26erqym3fs2dP2EdXdiESQcEuRCIo2IVIBAW7EImgYBciERTsQiRC6YkwZVHmckcsWaSovMZ8ZNJb5AtbzYbZpk6dGtqiVV8A4Pjx46GtCEUTYeotvUUrzAB8HO++++7QFklvy5YtC/t0dHTktn/qU58K++jKLkQiKNiFSAQFuxCJoGAXIhEU7EIkgoJdiEQYk/RmZn0ABgEMAxhy9+4q7w8zx1hWVhGKylpFauEVzRorutwRk8OicSwqNzJZkR2zqK4a2xeT8tgYs37R52bHhWXszZw5M7TddNNNoW3VqlWhbc6cObntM2bMCPtEEhsbp3pE2N+4+4d12I4QooHoNl6IRBhrsDuA18xso5mtrYdDQojGMNbb+C+6e7+ZzQbwupntcPe3Rr4h+yewFiheX10IMXbGdGV39/7s9xEAvwNwV8571rl7t7t3N6IUkBCiNgpHn5lNNrOpV14D+BqArfVyTAhRX8ZyG98B4HeZtHEDgP929/+t1qnI8k8RrAghk4WKLPEEFFuuqagEyB55WGHDqPjl5MmTwz5tbW2hjRX7ZNLQ9OnTc9tPnjwZ9mG2jz76qJAtWg6JjT3LbJs/f35oW758eWi77bbbQlt0rFl246FDh3LbaUyEliq4+14Any3aXwhRLnqIFiIRFOxCJIKCXYhEULALkQgKdiESofSCk5HMUETWYmusFf22HttmlGnEZD4mk507d65QvxMnToS2SGJrb28P+yxYsCC0ffrTny7Ub/bs2bntTF7r7+8PbQcOHAhtH34Y52FFUtT58+fDPqxo48KFC0PbokWLQtuxY8dCWyQd9vX1hX2ic2BwcDDsoyu7EImgYBciERTsQiSCgl2IRFCwC5EIpc7Gu3s4A81mtKOZejZryuqBdXZ2hjZWYyxK7ojqrQF8FvaPf/xjaGOzz6zmWrSU0OrVq8M+bMa96FhFddwWL15caHtMXYmOC+vX09MT9mGp2CzZhS3XtHVrnBC6f//+UbUDcYIPU3h0ZRciERTsQiSCgl2IRFCwC5EICnYhEkHBLkQilJ4IE8FqgkXSFkvumDdvXmiL5CkA6OjoCG1RcsekSZPCPrt27Qpts2bNCm1nzpwJbUzqi6Qyti8mXTFJlCWgRP4zaYjVT1uyZEloY8lLkWzL6taxunvROQDw84DJaB988EFu+6lTp8I+kfzKah7qyi5EIijYhUgEBbsQiaBgFyIRFOxCJIKCXYhEqCq9mdkzAL4B4Ii735a1tQH4NYAFAPoAPODucWG0GmCZRpHcweqB3X777aGN9WNLGk2cODG3nckdTMaJtgcA06ZNK9Qvkqi6urrCPkxeY/Xu9u3bF9p2796d284kUbbs0s033xza2Ge79dZbc9tZzUMmAzNplh3rIhlsTHqLfGSfq5Yr+88BrLmm7XEAb7j7UgBvZH8LIa5jqgZ7tt768Wua7wPwbPb6WQDfrLNfQog6U/SZvcPdB7LXh1BZ0VUIcR0z5q/LurubWfjQamZrAawF+HO5EKKxFI2+w2bWCQDZ7/wZBgDuvs7du929W8EuRPMoGn0vA3gke/0IgJfq444QolHUIr39CsA9AGaZ2UEA3wfwAwDPm9mjAPYBeKDWHUaSAbvqR9ltrFDi/PnzQxvLAGOFDTdv3pzbzjK59u7dG9pY1hiTw5h0eMstt+S2s2KOrLglK8y4Z8+e0Hbw4MHcdpYFyKS3ixcvhjaW/Thnzpzc9uPHr51z/its7KPltQBeCJRJYkNDQ7ntLAuQ+Rj2qfYGd38oMH1l1HsTQjQNPUQLkQgKdiESQcEuRCIo2IVIBAW7EIlQesHJSHpjmUaRbNTW1hb2YVljTOZjhQjffPPN3HYm4wwODoa2kydPhjYmDxaRmlgxROYHW6Osv78/tEVFMdnadyzLi2WNsW3OnTs3t52dH0zyimQygEuwrEhotGbh+fPnwz7Mxwhd2YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EIpUpvQ0NDYabXqlWrwn6RbcWKFWGfaP0sAHjhhRdCW29vb2g7fPhwbjvLQGLyCevH1jb7/Oc/H9qidduYhLZly5bQxuQ19tkieZNJRiwL8O233w5trOBklP24aNGisA+TAFlx0dOnT4c2JvUdOnQot51lYEbr2zFZWVd2IRJBwS5EIijYhUgEBbsQiaBgFyIRSp2NHz9+fJjgwerJRckMrC7Zzp07QxurC8dmYqPZ89bW1rDPmTNnQhvrx5J8ohl3IK51xvxgCRzMRzb+kY0lPDEbS0BhM+TR7D/bXpH6bgBf/ontL6pdx9SOaKZ+rMs/CSE+ASjYhUgEBbsQiaBgFyIRFOxCJIKCXYhEqGX5p2cAfAPAEXe/LWt7EsC3ABzN3vaEu79SbVsTJkzA0qVLc20rV64M+0Uy1O7du8M+GzduDG0sSYbVCougcgdJTGCy1owZM0JbVLMMiCUvVlvv7Nmzo94ewD83k9EimHTFPjNbkimCfS62jFOUgALwc4dtM5LYWNJQkUVSa+nxcwBrctp/4u53ZD9VA10I0VyqBru7vwUgLp8qhPhYMJZn9sfMrMfMnjGz+J5TCHFdUDTYnwKwGMAdAAYA/Ch6o5mtNbMNZrahSK1rIUR9KBTs7n7Y3Yfd/TKAnwG4i7x3nbt3u3s3m9wQQjSWQsFuZp0j/rwfQFzzSAhxXVCL9PYrAPcAmGVmBwF8H8A9ZnYHAAfQB+Dbtexs8uTJ+NznPpdri2qFAcCRI0dy23fs2BH2YZltrFYYy3iK5B8m47CMLFZjjElvN954Y2iL6pkx6YdlvTHYWEVZXkWlyKlTp4Y2JssNDw/ntrNHSpYhyGDHjB3raByLyI10P6Elw90fyml+ulo/IcT1hb5BJ0QiKNiFSAQFuxCJoGAXIhEU7EIkQqkFJ1tbW8PCkqyIYrQ80f79+8M+TGoqWlAwyvJikhGDfcmIyThFMvPYeLCsN5bZxoikrUmTJoV92HFhNrbNSHpjxRzZZ2bSFjsPmI/R8SwizbJx0pVdiERQsAuRCAp2IRJBwS5EIijYhUgEBbsQiVCq9NbS0hLKDKwgYpSFxOSkaH04AFixYkVoY5JXlB3GClhG0k+1fbF+URYgABw7diy3nWV5sYwyJv8w+WrixIm57UWzABcvXhzapk2bFtqiIpbROAFAb29vaJszZ05ou/POO0Nbe3t7aBsYGMhtZ+vDsbGK0JVdiERQsAuRCAp2IRJBwS5EIijYhUiE0mfjo2QBNrsYJREsXLgw7MOSRRYsWBDa2BJEx4/nr5Uxa9assA9LdmFqwtGjR0PbyZMnQ1uR2m/RzDnAkztY7b1Tp07ltjOVgfnBZrPZ8k+Rj9GxBICDBw+GNqa8fOYznwltTDGIzm927hRJUNKVXYhEULALkQgKdiESQcEuRCIo2IVIBAW7EIlQy/JPXQB+AaADleWe1rn7T82sDcCvASxAZQmoB9z9BNtWS0tLKJMw+SRKPojq2QF86RwmyzFJo62tLbd99uzZhba3a9eu0BYlRwC8Zlwk8bDxYDaWjMFkyggzC23R+ALAvHnzCvkRSYCsfmF/f39o27lzZ2hbtmxZaGNLdkXHjCWHRXIdk1hrubIPAfieuy8HsArAd8xsOYDHAbzh7ksBvJH9LYS4Tqka7O4+4O7vZq8HAWwHMBfAfQCezd72LIBvNspJIcTYGdUzu5ktALACwHoAHe5+5V7zECq3+UKI65Sag93MpgB4EcB33f2qNY+9UpEgtyqBma01sw1mtoEtlSyEaCw1BbuZjUcl0H/p7r/Nmg+bWWdm7wSQWz7F3de5e7e7d7NJCiFEY6ka7FaZPn0awHZ3//EI08sAHslePwLgpfq7J4SoF7VkvX0BwMMAtpjZpqztCQA/APC8mT0KYB+AB6ptqKWlJZR5WB20KFOKyTjskWHv3r2hjdVq6+rqym1n0huTjIrKa2yJn0jGYXdVzMYy81hWVpTBxo7ZzTffHNqisQf40kqRjPaXv/wl7MNkuWgpMgBYuXJlaGM19KIMvCLLYbFjUjXY3f0PAKIj9JVq/YUQ1wf6Bp0QiaBgFyIRFOxCJIKCXYhEULALkQilF5yMpDdWbDDKhmISyauvvhra1q9fH9qY1LRmzZrc9tWrV4d9WEYZy/RjBQpZgcso64llQ7HMPFYIlGWbRftjctLMmTNDW9Gst6jgJCsqyZbX2rdvX2j78MMPQ9s999wT2qIComzso2xEJr3pyi5EIijYhUgEBbsQiaBgFyIRFOxCJIKCXYhEKF16i+QmJg319vbmtv/pT38K+/T19YU2lhHHZJfNmzfntrNsLSaTMentxIm4dufWrVtDW3d3d277ihUrCvnBxoqtAzd9+vTcdpah1tnZGdrYunLsmEVFPVl2I5O82L7efPPN0LZq1arQFsmsrIBlJDeyY6kruxCJoGAXIhEU7EIkgoJdiERQsAuRCKXOxrt7+AV+tsxQlLjy2muvhX1YYk00UwzwWd9olpYlYrDZZzYjzJaGOnPmTGiLarWx2fibbroptLEkGaagROPPjsvRo0dD244dO0Lbtm3bQlukoLCEEXbM2Gd+7733Qtvbb78d2qLlzVhtwyg5jCkJurILkQgKdiESQcEuRCIo2IVIBAW7EImgYBciEapKb2bWBeAXqCzJ7ADWuftPzexJAN8CcEUvecLdX2HbGh4exqlTp3JtTL6K+kRL+wDA4OBgaGN14ZjsEi3hw5ZPYn6wpIpjx46FNlafLkpcYXIdkyKLLMsFxMs8sTptRRJaqtkOHTqU2/7RRx+FfVidvClTpoQ2No7Mx0hyZNuLzjn6uULLXxkC8D13f9fMpgLYaGavZ7afuPu/17ANIUSTqWWttwEAA9nrQTPbDmBuox0TQtSXUT2zm9kCACsAXPlK22Nm1mNmz5jZjDr7JoSoIzUHu5lNAfAigO+6+2kATwFYDOAOVK78Pwr6rTWzDWa2IXr2FkI0npqC3czGoxLov3T33wKAux9292F3vwzgZwDuyuvr7uvcvdvdu9nEkhCisVQNdqtMqz4NYLu7/3hE+8gaQvcDiGslCSGaTi2z8V8A8DCALWa2KWt7AsBDZnYHKnJcH4BvV9vQ0NBQKDMw+SqSIFjNMiavsYwnlgG2ZMmS3HZWi43Jg9GyPwCv/cb6ffDBB7ntTNbq6OgIbSzLi/kYPbJF/gFAT09PaNuyZUto27NnT2iLJEx3D/sw6Y2NB4Nl5kWyMzuvIgmQSb21zMb/AUCeaEo1dSHE9YW+QSdEIijYhUgEBbsQiaBgFyIRFOxCJEKpBSdZ1huTGaJss3vvvTfsw4o5XrhwIbQxGSqS+lhG2fHjx0Mb85FlAbLMsajAItveokWLQhvL8nr//fdDWySHsWy+/fv3hzYmYbLxjyQ2Jr+yopgs04/JXocPHw5tkdTHjlnk4/nz58M+urILkQgKdiESQcEuRCIo2IVIBAW7EImgYBciEUqV3i5duhRKEEzuiKQhthYW296JEydCG5MAoyKKUVFDgEsuTCZhhR7ZZ4ukJuYHK1LI5CSWiTYwMDDqfTEby1JjUmqU/cjWRGMwuZRJgGwtw0h6O3v2bNgnOgfYfnRlFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCKUKr2dPXsWmzZtyrUx+SQq8sdKU7Ospvb29tDGpKbe3t7cdlbwcPv27aHt3LlzoY0V4GTFNKOsQpZ9xySvqEBotX5RUUwmeTHZ8+LFi6GNFYhkWWoRTOYrmi3H/I/Ob/a5iqAruxCJoGAXIhEU7EIkgoJdiERQsAuRCFWn+8xsIoC3AEzI3v8bd/++mS0E8ByAmQA2AnjY3eMpR1RmRqMaZNFMNxDPMLP6aMzGElBYokNfX19uO1taqWhyRNEaetFnYyvoshlmNotcJLnj8uXLYR9mY7BZ62ibbBkntr0oGaraNovsr8j2qH+h5a9cAPBld/8sKsszrzGzVQB+COAn7r4EwAkAj9awLSFEk6ga7F7hiqA6PvtxAF8G8Jus/VkA32yIh0KIulDr+uzjshVcjwB4HcAeACfd/cp93EEAcxvjohCiHtQU7O4+7O53AJgH4C4At9a6AzNba2YbzGwDew4VQjSWUc3Gu/tJAL8HsBrAdDO7MrMwD0BuFX93X+fu3e7ezSaChBCNpWqwm1m7mU3PXk8C8FUA21EJ+r/L3vYIgJca5aQQYuzU8k37TgDPmtk4VP45PO/u/2Nm2wA8Z2b/CuA9AE9X29DQ0FC4dBFLCtm3b19ue9E6bUxOYokTke+nT58utD12p1M0CSLyhfnBJB5GkeQUJq8VSVoBuATIpKgisEQetq8idQOL3AkzH6qeUe7eA2BFTvteVJ7fhRAfA/QNOiESQcEuRCIo2IVIBAW7EImgYBciEYzV26r7zsyOAriio80CkK9llYv8uBr5cTUfNz/mu3tukcVSg/2qHZttcPfupuxcfsiPBP3QbbwQiaBgFyIRmhns65q475HIj6uRH1fzifGjac/sQohy0W28EInQlGA3szVmttPMdpvZ483wIfOjz8y2mNkmM9tQ4n6fMbMjZrZ1RFubmb1uZr3Z7xlN8uNJM+vPxmSTmX29BD+6zOz3ZrbNzN43s3/I2ksdE+JHqWNiZhPN7M9mtjnz41+y9oVmtj6Lm1+bWbxeVh7uXuoPgHGolLVaBKAVwGYAy8v2I/OlD8CsJuz3SwDuBLB1RNu/AXg8e/04gB82yY8nAfxjyePRCeDO7PVUALsALC97TIgfpY4JAAMwJXs9HsB6AKsAPA/gwaz9PwD8/Wi224wr+10Adrv7Xq+Unn4OwH1N8KNpuPtbAK5dafE+VAp3AiUV8Az8KB13H3D3d7PXg6gUR5mLkseE+FEqXqHuRV6bEexzARwY8Xczi1U6gNfMbKOZrW2SD1focPeB7PUhAB1N9OUxM+vJbvMb/jgxEjNbgEr9hPVo4phc4wdQ8pg0oshr6hN0X3T3OwH8LYDvmNmXmu0QUPnPjso/ombwFIDFqKwRMADgR2Xt2MymAHgRwHfd/aqSO2WOSY4fpY+Jj6HIa0Qzgr0fQNeIv8NilY3G3fuz30cA/A7Nrbxz2Mw6ASD7HS8z00Dc/XB2ol0G8DOUNCZmNh6VAPulu/82ay59TPL8aNaYZPsedZHXiGYE+zsAlmYzi60AHgTwctlOmNlkM5t65TWArwHYyns1lJdRKdwJNLGA55XgyrgfJYyJVQqnPQ1gu7v/eISp1DGJ/Ch7TBpW5LWsGcZrZhu/jspM5x4A/9QkHxahogRsBvB+mX4A+BUqt4OXUHn2ehSVNfPeANAL4P8AtDXJj/8CsAVADyrB1lmCH19E5Ra9B8Cm7OfrZY8J8aPUMQFwOypFXHtQ+cfyzyPO2T8D2A3gBQATRrNdfYNOiERIfYJOiGRQsAuRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJML/A8V3pNSnaqjeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2BURc2sTmnM",
        "colab_type": "code",
        "outputId": "62e5e32b-0cc0-4edb-e79b-b3d415130563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "print(X_val.shape, y_val.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 32, 32) (42000,)\n",
            "(18000, 32, 32) (18000,)\n",
            "(60000, 32, 32) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1epbrGwg6kB-",
        "colab_type": "code",
        "outputId": "8cec4042-c302-4275-9537-9003e52fc228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reshape features.\n",
        "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
        "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 1024) (18000, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sF0SmO387k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize features.\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Gnffm388nC",
        "colab_type": "code",
        "outputId": "4a6cfcbd-e61e-44c7-c82d-6e882c68cc5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# One-hot encode the target\n",
        "print(np.unique(y_train))\n",
        "print(np.unique(y_test))\n",
        "y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CAak4psEN--",
        "colab_type": "code",
        "outputId": "9ecb1c2c-615d-4de5-dcd4-95764cb46e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_test[2])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KntlvnQEzmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create basic model and check the accuracy and loss.\n",
        "\n",
        "def prepapreBasicModel(epochs, lr,lVal,X_train,y_train):\n",
        "\n",
        "  hidden_nodes = 256\n",
        "  output_nodes = 10\n",
        "  input_shape = X_train.shape[1]\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(hidden_nodes,input_shape = (input_shape,)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(hidden_nodes))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(output_nodes,kernel_regularizer=regularizers.l2(lVal)))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  sgd = optimizers.Adam(lr)\n",
        "  # optimizers.SGD(learning_rate=lr,momentum=0.9)\n",
        "  # complie model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "  #Model summary\n",
        "  model.summary()\n",
        "\n",
        "  #Fit model\n",
        "  model.fit(X_train,y_train,epochs=epochs,batch_size=1000,verbose=True)\n",
        "  print(f'Learning Rate: {lr} ')\n",
        "  print(f'Lambda: {lVal}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVatHe3gKsI8",
        "colab_type": "code",
        "outputId": "6844370d-cb6c-48d8-e44e-c60592d152cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "lr = 0.001\n",
        "Lambda = 0\n",
        "prepapreBasicModel(1,lr,Lambda,X_train,y_train)\n",
        "# As we can see , the accuracy is almost 10."
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3017 - accuracy: 0.1241\n",
            "Learning Rate: 0.001 \n",
            "Lambda: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQSXegO_K1R9",
        "colab_type": "code",
        "outputId": "966d6f83-51f3-4565-fa16-e94fd3c2c4e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Let's try increasing the Lambda value, and check for increase in loss.\n",
        "lr = 0.001\n",
        "Lambda = 1e3\n",
        "prepapreBasicModel(1,lr,Lambda,X_train,y_train)\n",
        "# yes, there is a increase in loss."
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 13099.1904 - accuracy: 0.1211\n",
            "Learning Rate: 0.001 \n",
            "Lambda: 1000.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMX1TvbUbZWm",
        "colab_type": "code",
        "outputId": "8105e88a-ccca-4f34-8348-3d285228644f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Now, let's overfit the model by taking subset data from original data.\n",
        "X_train_subset = X_train[0:20]\n",
        "y_train_subset = y_train[0:20]\n",
        "print(X_train_subset.shape,y_train_subset.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 1024) (20, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcX4WZd7dr2s",
        "colab_type": "code",
        "outputId": "e07541fc-79dd-4467-afaf-551fcfda126b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "lr = 0.001\n",
        "Lambda = 0\n",
        "prepapreBasicModel(500,lr,Lambda,X_train_subset,y_train_subset)\n",
        "# as we can see the model is overfitting."
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_26 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5235 - accuracy: 0.1000\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 766us/step - loss: 2.0071 - accuracy: 0.2500\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 807us/step - loss: 1.8347 - accuracy: 0.3500\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 764us/step - loss: 1.7691 - accuracy: 0.4000\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6937 - accuracy: 0.3500\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5960 - accuracy: 0.6000\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5077 - accuracy: 0.6000\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4258 - accuracy: 0.6000\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 800us/step - loss: 1.3439 - accuracy: 0.6500\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2648 - accuracy: 0.6000\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1859 - accuracy: 0.6500\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 994us/step - loss: 1.1120 - accuracy: 0.7500\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0341 - accuracy: 0.7000\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 753us/step - loss: 0.9568 - accuracy: 0.7500\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 830us/step - loss: 0.8846 - accuracy: 0.8000\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 753us/step - loss: 0.8200 - accuracy: 0.8500\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 737us/step - loss: 0.7575 - accuracy: 0.9000\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 791us/step - loss: 0.6935 - accuracy: 0.9000\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 791us/step - loss: 0.6360 - accuracy: 0.9500\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 834us/step - loss: 0.5799 - accuracy: 0.9000\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 944us/step - loss: 0.5259 - accuracy: 0.9500\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 839us/step - loss: 0.4744 - accuracy: 1.0000\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 743us/step - loss: 0.4257 - accuracy: 1.0000\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 1.0000\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 760us/step - loss: 0.3372 - accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 1.0000\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 0.2624 - accuracy: 1.0000\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 1.0000\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 763us/step - loss: 0.1999 - accuracy: 1.0000\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 1.0000\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 1.0000\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 1.0000\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 1.0000\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 1.0000\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 1.0000\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 784us/step - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 878us/step - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 899us/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 983us/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 865us/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 987us/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 978us/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 791us/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 876us/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 812us/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 784us/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 955us/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 950us/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 980us/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 831us/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 785us/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 882us/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 774us/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 930us/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 750us/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 862us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 881us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 763us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 787us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 766us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 991us/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9625e-04 - accuracy: 1.0000\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8751e-04 - accuracy: 1.0000\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.7879e-04 - accuracy: 1.0000\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.6996e-04 - accuracy: 1.0000\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.6126e-04 - accuracy: 1.0000\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.5256e-04 - accuracy: 1.0000\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.4376e-04 - accuracy: 1.0000\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.3521e-04 - accuracy: 1.0000\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 885us/step - loss: 9.2672e-04 - accuracy: 1.0000\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.1811e-04 - accuracy: 1.0000\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 873us/step - loss: 9.0929e-04 - accuracy: 1.0000\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0047e-04 - accuracy: 1.0000\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 749us/step - loss: 8.9155e-04 - accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.8269e-04 - accuracy: 1.0000\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.7441e-04 - accuracy: 1.0000\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6603e-04 - accuracy: 1.0000\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.5755e-04 - accuracy: 1.0000\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.4968e-04 - accuracy: 1.0000\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.4213e-04 - accuracy: 1.0000\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3458e-04 - accuracy: 1.0000\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.2695e-04 - accuracy: 1.0000\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1932e-04 - accuracy: 1.0000\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.1176e-04 - accuracy: 1.0000\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 789us/step - loss: 8.0418e-04 - accuracy: 1.0000\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 769us/step - loss: 7.9674e-04 - accuracy: 1.0000\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8935e-04 - accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 820us/step - loss: 7.8198e-04 - accuracy: 1.0000\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 802us/step - loss: 7.7464e-04 - accuracy: 1.0000\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 769us/step - loss: 7.6733e-04 - accuracy: 1.0000\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.6016e-04 - accuracy: 1.0000\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.5299e-04 - accuracy: 1.0000\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4586e-04 - accuracy: 1.0000\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3878e-04 - accuracy: 1.0000\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 752us/step - loss: 7.3177e-04 - accuracy: 1.0000\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2487e-04 - accuracy: 1.0000\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1795e-04 - accuracy: 1.0000\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1121e-04 - accuracy: 1.0000\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0449e-04 - accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9787e-04 - accuracy: 1.0000\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.9124e-04 - accuracy: 1.0000\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8466e-04 - accuracy: 1.0000\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 743us/step - loss: 6.7820e-04 - accuracy: 1.0000\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7175e-04 - accuracy: 1.0000\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 803us/step - loss: 6.6535e-04 - accuracy: 1.0000\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5904e-04 - accuracy: 1.0000\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5269e-04 - accuracy: 1.0000\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4650e-04 - accuracy: 1.0000\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4041e-04 - accuracy: 1.0000\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3434e-04 - accuracy: 1.0000\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 732us/step - loss: 6.2837e-04 - accuracy: 1.0000\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 749us/step - loss: 6.2243e-04 - accuracy: 1.0000\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1655e-04 - accuracy: 1.0000\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.1078e-04 - accuracy: 1.0000\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0504e-04 - accuracy: 1.0000\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 787us/step - loss: 5.9939e-04 - accuracy: 1.0000\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9378e-04 - accuracy: 1.0000\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8823e-04 - accuracy: 1.0000\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8272e-04 - accuracy: 1.0000\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7722e-04 - accuracy: 1.0000\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.7185e-04 - accuracy: 1.0000\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.6655e-04 - accuracy: 1.0000\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6121e-04 - accuracy: 1.0000\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5598e-04 - accuracy: 1.0000\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5089e-04 - accuracy: 1.0000\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4571e-04 - accuracy: 1.0000\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4076e-04 - accuracy: 1.0000\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3583e-04 - accuracy: 1.0000\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3088e-04 - accuracy: 1.0000\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2602e-04 - accuracy: 1.0000\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2127e-04 - accuracy: 1.0000\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1651e-04 - accuracy: 1.0000\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 861us/step - loss: 5.1174e-04 - accuracy: 1.0000\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0718e-04 - accuracy: 1.0000\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0260e-04 - accuracy: 1.0000\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9800e-04 - accuracy: 1.0000\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9356e-04 - accuracy: 1.0000\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 982us/step - loss: 4.8921e-04 - accuracy: 1.0000\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 4.8479e-04 - accuracy: 1.0000\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8044e-04 - accuracy: 1.0000\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7623e-04 - accuracy: 1.0000\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7206e-04 - accuracy: 1.0000\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6782e-04 - accuracy: 1.0000\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6372e-04 - accuracy: 1.0000\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 726us/step - loss: 4.5968e-04 - accuracy: 1.0000\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5566e-04 - accuracy: 1.0000\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5161e-04 - accuracy: 1.0000\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4770e-04 - accuracy: 1.0000\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4382e-04 - accuracy: 1.0000\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3997e-04 - accuracy: 1.0000\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3621e-04 - accuracy: 1.0000\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3245e-04 - accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2877e-04 - accuracy: 1.0000\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2511e-04 - accuracy: 1.0000\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2148e-04 - accuracy: 1.0000\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1793e-04 - accuracy: 1.0000\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1444e-04 - accuracy: 1.0000\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1098e-04 - accuracy: 1.0000\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0757e-04 - accuracy: 1.0000\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0410e-04 - accuracy: 1.0000\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0081e-04 - accuracy: 1.0000\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9751e-04 - accuracy: 1.0000\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9421e-04 - accuracy: 1.0000\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9095e-04 - accuracy: 1.0000\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8782e-04 - accuracy: 1.0000\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8465e-04 - accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8151e-04 - accuracy: 1.0000\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7838e-04 - accuracy: 1.0000\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7543e-04 - accuracy: 1.0000\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7241e-04 - accuracy: 1.0000\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6939e-04 - accuracy: 1.0000\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6649e-04 - accuracy: 1.0000\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6356e-04 - accuracy: 1.0000\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6068e-04 - accuracy: 1.0000\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5782e-04 - accuracy: 1.0000\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5509e-04 - accuracy: 1.0000\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5231e-04 - accuracy: 1.0000\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4951e-04 - accuracy: 1.0000\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4682e-04 - accuracy: 1.0000\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4415e-04 - accuracy: 1.0000\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4149e-04 - accuracy: 1.0000\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3887e-04 - accuracy: 1.0000\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3628e-04 - accuracy: 1.0000\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3376e-04 - accuracy: 1.0000\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3119e-04 - accuracy: 1.0000\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2874e-04 - accuracy: 1.0000\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2624e-04 - accuracy: 1.0000\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2379e-04 - accuracy: 1.0000\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2141e-04 - accuracy: 1.0000\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1903e-04 - accuracy: 1.0000\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1667e-04 - accuracy: 1.0000\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1436e-04 - accuracy: 1.0000\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1202e-04 - accuracy: 1.0000\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.0976e-04 - accuracy: 1.0000\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 795us/step - loss: 3.0751e-04 - accuracy: 1.0000\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0529e-04 - accuracy: 1.0000\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0312e-04 - accuracy: 1.0000\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0099e-04 - accuracy: 1.0000\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9881e-04 - accuracy: 1.0000\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9670e-04 - accuracy: 1.0000\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9458e-04 - accuracy: 1.0000\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9247e-04 - accuracy: 1.0000\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9043e-04 - accuracy: 1.0000\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8838e-04 - accuracy: 1.0000\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8639e-04 - accuracy: 1.0000\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8439e-04 - accuracy: 1.0000\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8245e-04 - accuracy: 1.0000\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8050e-04 - accuracy: 1.0000\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7858e-04 - accuracy: 1.0000\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 774us/step - loss: 2.7668e-04 - accuracy: 1.0000\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7477e-04 - accuracy: 1.0000\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7293e-04 - accuracy: 1.0000\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7111e-04 - accuracy: 1.0000\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6928e-04 - accuracy: 1.0000\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6748e-04 - accuracy: 1.0000\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6573e-04 - accuracy: 1.0000\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6393e-04 - accuracy: 1.0000\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6220e-04 - accuracy: 1.0000\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 898us/step - loss: 2.6050e-04 - accuracy: 1.0000\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5874e-04 - accuracy: 1.0000\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5703e-04 - accuracy: 1.0000\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 832us/step - loss: 2.5541e-04 - accuracy: 1.0000\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5374e-04 - accuracy: 1.0000\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 822us/step - loss: 2.5202e-04 - accuracy: 1.0000\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5044e-04 - accuracy: 1.0000\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4884e-04 - accuracy: 1.0000\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.4718e-04 - accuracy: 1.0000\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 761us/step - loss: 2.4560e-04 - accuracy: 1.0000\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 966us/step - loss: 2.4407e-04 - accuracy: 1.0000\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4250e-04 - accuracy: 1.0000\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4100e-04 - accuracy: 1.0000\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3946e-04 - accuracy: 1.0000\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3799e-04 - accuracy: 1.0000\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3652e-04 - accuracy: 1.0000\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3499e-04 - accuracy: 1.0000\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3358e-04 - accuracy: 1.0000\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3212e-04 - accuracy: 1.0000\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3070e-04 - accuracy: 1.0000\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2928e-04 - accuracy: 1.0000\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2787e-04 - accuracy: 1.0000\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.2648e-04 - accuracy: 1.0000\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2512e-04 - accuracy: 1.0000\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.2378e-04 - accuracy: 1.0000\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2241e-04 - accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2108e-04 - accuracy: 1.0000\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1978e-04 - accuracy: 1.0000\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.1843e-04 - accuracy: 1.0000\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1720e-04 - accuracy: 1.0000\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1590e-04 - accuracy: 1.0000\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 865us/step - loss: 2.1461e-04 - accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1334e-04 - accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 865us/step - loss: 2.1209e-04 - accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1086e-04 - accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 751us/step - loss: 2.0965e-04 - accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0843e-04 - accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0725e-04 - accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 968us/step - loss: 2.0602e-04 - accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 871us/step - loss: 2.0485e-04 - accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0368e-04 - accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 751us/step - loss: 2.0253e-04 - accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 773us/step - loss: 2.0139e-04 - accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 786us/step - loss: 2.0026e-04 - accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9914e-04 - accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9802e-04 - accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9693e-04 - accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9582e-04 - accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 908us/step - loss: 1.9475e-04 - accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 834us/step - loss: 1.9367e-04 - accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9262e-04 - accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9156e-04 - accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 842us/step - loss: 1.9052e-04 - accuracy: 1.0000\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 792us/step - loss: 1.8947e-04 - accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 748us/step - loss: 1.8844e-04 - accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8742e-04 - accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8641e-04 - accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8543e-04 - accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8443e-04 - accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 906us/step - loss: 1.8342e-04 - accuracy: 1.0000\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8248e-04 - accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8153e-04 - accuracy: 1.0000\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8058e-04 - accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7962e-04 - accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 782us/step - loss: 1.7873e-04 - accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7777e-04 - accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7686e-04 - accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7596e-04 - accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7507e-04 - accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7414e-04 - accuracy: 1.0000\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7323e-04 - accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7235e-04 - accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7148e-04 - accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7065e-04 - accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6977e-04 - accuracy: 1.0000\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 764us/step - loss: 1.6892e-04 - accuracy: 1.0000\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 783us/step - loss: 1.6807e-04 - accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6725e-04 - accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 851us/step - loss: 1.6642e-04 - accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6558e-04 - accuracy: 1.0000\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6475e-04 - accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6397e-04 - accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6317e-04 - accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 914us/step - loss: 1.6236e-04 - accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6158e-04 - accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6078e-04 - accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5996e-04 - accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5922e-04 - accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5848e-04 - accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5767e-04 - accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5697e-04 - accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5623e-04 - accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5544e-04 - accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 770us/step - loss: 1.5471e-04 - accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5401e-04 - accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5325e-04 - accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5254e-04 - accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5185e-04 - accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5113e-04 - accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5042e-04 - accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4971e-04 - accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4903e-04 - accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4834e-04 - accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4766e-04 - accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4699e-04 - accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4632e-04 - accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4565e-04 - accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4499e-04 - accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4435e-04 - accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4369e-04 - accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4304e-04 - accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4241e-04 - accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4176e-04 - accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4113e-04 - accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4050e-04 - accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3989e-04 - accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3915e-04 - accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 772us/step - loss: 1.3862e-04 - accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3789e-04 - accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 807us/step - loss: 1.3729e-04 - accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3666e-04 - accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 798us/step - loss: 1.3598e-04 - accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 1.3540e-04 - accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3475e-04 - accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3413e-04 - accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3346e-04 - accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3291e-04 - accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3222e-04 - accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3151e-04 - accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3084e-04 - accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3015e-04 - accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2948e-04 - accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2876e-04 - accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2807e-04 - accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2733e-04 - accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2659e-04 - accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2592e-04 - accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2522e-04 - accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2452e-04 - accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2371e-04 - accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 998us/step - loss: 1.2303e-04 - accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2225e-04 - accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2151e-04 - accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2077e-04 - accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1996e-04 - accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1929e-04 - accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1848e-04 - accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1778e-04 - accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1698e-04 - accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1619e-04 - accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1547e-04 - accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1462e-04 - accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1391e-04 - accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1315e-04 - accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1234e-04 - accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1158e-04 - accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1087e-04 - accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1005e-04 - accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0937e-04 - accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0856e-04 - accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0777e-04 - accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0716e-04 - accuracy: 1.0000\n",
            "Learning Rate: 0.001 \n",
            "Lambda: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwdhn2tUd5jP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We checked initial loss\n",
        "# We observed increase in loss by changing learning rate.\n",
        "# And we checked model is overfitting on subset of training data. \n",
        "# We can say that, our base model is ready."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgCBCmjoi8jC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now let's build our upgraded model based on previous model.\n",
        "# We considred that our previous model as our base model. Because we tested , base loss and overfitting."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-ssHGvgkRiy",
        "colab_type": "code",
        "outputId": "a36012d0-f2a6-4fba-ee01-76f3a9614758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Try to figure out Lmabda and LearningRate.\n",
        "# We start with smalledt values.\n",
        "# We will use our basic model.\n",
        "learningRate = 1e-7\n",
        "Lambda = 1e-7\n",
        "prepapreBasicModel(50,learningRate,Lambda,X_train,y_train)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_32 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3253 - accuracy: 0.0995\n",
            "Epoch 2/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3246 - accuracy: 0.0995\n",
            "Epoch 3/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3239 - accuracy: 0.0993\n",
            "Epoch 4/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3232 - accuracy: 0.0992\n",
            "Epoch 5/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3225 - accuracy: 0.0994\n",
            "Epoch 6/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3218 - accuracy: 0.0994\n",
            "Epoch 7/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3212 - accuracy: 0.0996\n",
            "Epoch 8/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3206 - accuracy: 0.0997\n",
            "Epoch 9/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3200 - accuracy: 0.0996\n",
            "Epoch 10/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3195 - accuracy: 0.0993\n",
            "Epoch 11/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3189 - accuracy: 0.0993\n",
            "Epoch 12/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3184 - accuracy: 0.0992\n",
            "Epoch 13/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3179 - accuracy: 0.0991\n",
            "Epoch 14/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3174 - accuracy: 0.0993\n",
            "Epoch 15/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3169 - accuracy: 0.0990\n",
            "Epoch 16/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3165 - accuracy: 0.0990\n",
            "Epoch 17/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3160 - accuracy: 0.0988\n",
            "Epoch 18/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3156 - accuracy: 0.0987\n",
            "Epoch 19/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3152 - accuracy: 0.0986\n",
            "Epoch 20/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3148 - accuracy: 0.0985\n",
            "Epoch 21/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3144 - accuracy: 0.0982\n",
            "Epoch 22/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3140 - accuracy: 0.0979\n",
            "Epoch 23/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3137 - accuracy: 0.0980\n",
            "Epoch 24/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3133 - accuracy: 0.0977\n",
            "Epoch 25/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3130 - accuracy: 0.0977\n",
            "Epoch 26/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3127 - accuracy: 0.0975\n",
            "Epoch 27/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3123 - accuracy: 0.0974\n",
            "Epoch 28/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3120 - accuracy: 0.0973\n",
            "Epoch 29/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3117 - accuracy: 0.0972\n",
            "Epoch 30/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3114 - accuracy: 0.0972\n",
            "Epoch 31/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3112 - accuracy: 0.0971\n",
            "Epoch 32/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3109 - accuracy: 0.0969\n",
            "Epoch 33/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3106 - accuracy: 0.0966\n",
            "Epoch 34/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3104 - accuracy: 0.0961\n",
            "Epoch 35/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3101 - accuracy: 0.0959\n",
            "Epoch 36/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3099 - accuracy: 0.0957\n",
            "Epoch 37/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3097 - accuracy: 0.0957\n",
            "Epoch 38/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3094 - accuracy: 0.0957\n",
            "Epoch 39/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3092 - accuracy: 0.0953\n",
            "Epoch 40/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3090 - accuracy: 0.0951\n",
            "Epoch 41/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3088 - accuracy: 0.0954\n",
            "Epoch 42/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3086 - accuracy: 0.0951\n",
            "Epoch 43/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3084 - accuracy: 0.0946\n",
            "Epoch 44/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3082 - accuracy: 0.0943\n",
            "Epoch 45/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3080 - accuracy: 0.0941\n",
            "Epoch 46/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3078 - accuracy: 0.0939\n",
            "Epoch 47/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3077 - accuracy: 0.0936\n",
            "Epoch 48/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3075 - accuracy: 0.0929\n",
            "Epoch 49/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3073 - accuracy: 0.0928\n",
            "Epoch 50/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 2.3072 - accuracy: 0.0927\n",
            "Learning Rate: 1e-07 \n",
            "Lambda: 1e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRJUTh50lBUY",
        "colab_type": "code",
        "outputId": "ad38bbcb-5253-4c6e-e7cf-e61a80621b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# As we can see there is no big change in loss and accuracy.\n",
        "# That tells us that \"LearningRate\" is very low.\n",
        "# Now let's by increasing \"LearningRate\" and keep \"Lambda\" as it was.\n",
        "learningRate = 1e8\n",
        "Lambda = 1e-7\n",
        "prepapreBasicModel(50,learningRate,Lambda,X_train,y_train)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_44 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0998\n",
            "Epoch 2/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 3/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 4/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 5/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 6/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 7/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 8/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 9/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 10/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 11/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 12/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 13/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 14/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 15/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 16/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 17/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 18/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 19/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 20/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 21/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 22/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 23/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 24/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 25/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 26/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 27/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 28/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 29/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 30/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 31/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 32/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 33/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 34/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 35/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 36/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 37/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 38/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 39/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 40/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 41/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 42/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 43/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 44/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 45/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 46/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 47/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 48/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 49/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Epoch 50/50\n",
            "42/42 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0997\n",
            "Learning Rate: 100000000.0 \n",
            "Lambda: 1e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FevX7DzKjgV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepapreUpdatedModel(epochs,learningRate,lVal,X_train,y_train,X_test,y_test):\n",
        "  hidden_nodes = 256\n",
        "  output_nodes = 10\n",
        "  input_shape = X_train.shape[1]\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(hidden_nodes,input_shape = (input_shape,)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(hidden_nodes))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(output_nodes,kernel_regularizer=regularizers.l2(lVal)))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  sgd = optimizers.Adam(learning_rate=learningRate)\n",
        "  # optimizers.SGD(learning_rate=learningRate,momentum=0.9)\n",
        "  # complie model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "  #Model summary\n",
        "  model.summary()\n",
        "\n",
        "  #Fit model\n",
        "  model.fit(X_train,y_train,epochs=epochs,batch_size=100,verbose=True)\n",
        "  score = model.evaluate(X_test,y_test,verbose=False)\n",
        "  print(f'Learning Rate: {learningRate}  and Lambda: {lVal} and score: {score}')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Jpj7HUn11i",
        "colab_type": "code",
        "outputId": "ab6c6fa9-d749-4d33-cdef-5437f5afc90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# See loss is exploding. That shows us \"LearningRate\" is very high.\n",
        "# And we can say that the we got \"LearningRate\", that would be between \"lowest=1e-7\" and \"Heighest=1e-4\"\n",
        "\n",
        "for val in range(1,10):\n",
        "  epochs = 100\n",
        "  lr = math.pow(10,np.random.uniform(-7,8))\n",
        "  Lambda = math.pow(10,np.random.uniform(-7,-2))\n",
        "  print(f\"Counter: {val}/{str(10)}\")\n",
        "  prepapreUpdatedModel(epochs,lr,Lambda,X_train,y_train,X_test,y_test)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter: 1/10\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_47 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 120975974459244544.0000 - accuracy: 0.0985\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 45373632.0000 - accuracy: 0.1011\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 45101416.0000 - accuracy: 0.1033\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 44849988.0000 - accuracy: 0.1010\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 44615048.0000 - accuracy: 0.1004\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 44393364.0000 - accuracy: 0.1009\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 44175088.0000 - accuracy: 0.1008\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 43952816.0000 - accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 43717188.0000 - accuracy: 0.0993\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 43467864.0000 - accuracy: 0.0985\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 43201988.0000 - accuracy: 0.1003\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 42920224.0000 - accuracy: 0.0995\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 42626624.0000 - accuracy: 0.0993\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 42328604.0000 - accuracy: 0.1001\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 42028932.0000 - accuracy: 0.1001\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 41735864.0000 - accuracy: 0.1015\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 41450732.0000 - accuracy: 0.1006\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 41179204.0000 - accuracy: 0.1023\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 40921680.0000 - accuracy: 0.1006\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 40680016.0000 - accuracy: 0.0999\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 40453088.0000 - accuracy: 0.1007\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 40236940.0000 - accuracy: 0.1006\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 40038600.0000 - accuracy: 0.0998\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39854316.0000 - accuracy: 0.1016\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39688996.0000 - accuracy: 0.0991\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39543344.0000 - accuracy: 0.0988\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39418776.0000 - accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39315712.0000 - accuracy: 0.0994\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39234304.0000 - accuracy: 0.0993\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39167776.0000 - accuracy: 0.1001\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39117444.0000 - accuracy: 0.0978\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39078424.0000 - accuracy: 0.1002\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39049300.0000 - accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39029164.0000 - accuracy: 0.1007\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 39010540.0000 - accuracy: 0.1002\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38998924.0000 - accuracy: 0.1020\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38987752.0000 - accuracy: 0.1009\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38978492.0000 - accuracy: 0.0992\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38969920.0000 - accuracy: 0.1008\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38963516.0000 - accuracy: 0.1000\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38956232.0000 - accuracy: 0.0997\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38950780.0000 - accuracy: 0.1003\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38943980.0000 - accuracy: 0.0999\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38934776.0000 - accuracy: 0.0989\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38926688.0000 - accuracy: 0.1012\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38917184.0000 - accuracy: 0.1015\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38905092.0000 - accuracy: 0.0980\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38888244.0000 - accuracy: 0.0986\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38869320.0000 - accuracy: 0.1031\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38845876.0000 - accuracy: 0.0964\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38819768.0000 - accuracy: 0.0998\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38787216.0000 - accuracy: 0.1009\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38749844.0000 - accuracy: 0.0976\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38703748.0000 - accuracy: 0.1014\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38649000.0000 - accuracy: 0.0985\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38586748.0000 - accuracy: 0.0998\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38511292.0000 - accuracy: 0.0998\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38424192.0000 - accuracy: 0.1028\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38324592.0000 - accuracy: 0.0996\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38208008.0000 - accuracy: 0.0982\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 38073744.0000 - accuracy: 0.1003\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 37923832.0000 - accuracy: 0.1007\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 37755284.0000 - accuracy: 0.1015\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 37563780.0000 - accuracy: 0.1005\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 37354472.0000 - accuracy: 0.1012\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 37123168.0000 - accuracy: 0.0997\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 36870896.0000 - accuracy: 0.0997\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 36594852.0000 - accuracy: 0.0962\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 36294060.0000 - accuracy: 0.1001\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 35967776.0000 - accuracy: 0.0973\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 35610096.0000 - accuracy: 0.1029\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 35219192.0000 - accuracy: 0.1021\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 34787132.0000 - accuracy: 0.0996\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 34305988.0000 - accuracy: 0.1001\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 33770776.0000 - accuracy: 0.0982\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 33172244.0000 - accuracy: 0.0979\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 32500298.0000 - accuracy: 0.1004\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 31752436.0000 - accuracy: 0.0987\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 30918222.0000 - accuracy: 0.0993\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 29992286.0000 - accuracy: 0.0996\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 28971118.0000 - accuracy: 0.0990\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 27853322.0000 - accuracy: 0.0988\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 26636296.0000 - accuracy: 0.0987\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 25319516.0000 - accuracy: 0.1002\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 23905006.0000 - accuracy: 0.1011\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 22396610.0000 - accuracy: 0.1022\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 20802508.0000 - accuracy: 0.1019\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 19133856.0000 - accuracy: 0.1013\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 17407978.0000 - accuracy: 0.0994\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 15644832.0000 - accuracy: 0.1013\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 13869368.0000 - accuracy: 0.1004\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 12112324.0000 - accuracy: 0.1014\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 10402075.0000 - accuracy: 0.1007\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 8769346.0000 - accuracy: 0.1005\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 7246230.5000 - accuracy: 0.0977\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5856392.5000 - accuracy: 0.1018\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4625094.5000 - accuracy: 0.0999\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3571876.2500 - accuracy: 0.1013\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2699854.5000 - accuracy: 0.1014\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2006605.3750 - accuracy: 0.1009\n",
            "Learning Rate: 30760.52136365149  and Lambda: 5.198085657908594e-07 and score: [1720550.0, 0.09822222590446472]\n",
            "Counter: 2/10\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_50 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3665 - accuracy: 0.0991\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3169 - accuracy: 0.1010\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3048 - accuracy: 0.1064\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3003 - accuracy: 0.1126\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2975 - accuracy: 0.1206\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2951 - accuracy: 0.1263\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2930 - accuracy: 0.1305\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2913 - accuracy: 0.1371\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2897 - accuracy: 0.1397\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2882 - accuracy: 0.1449\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2866 - accuracy: 0.1467\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2851 - accuracy: 0.1525\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2836 - accuracy: 0.1526\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2821 - accuracy: 0.1574\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2805 - accuracy: 0.1580\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2789 - accuracy: 0.1644\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2775 - accuracy: 0.1661\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2760 - accuracy: 0.1681\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2745 - accuracy: 0.1734\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2729 - accuracy: 0.1753\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2713 - accuracy: 0.1790\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2697 - accuracy: 0.1842\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2683 - accuracy: 0.1877\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2668 - accuracy: 0.1915\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2653 - accuracy: 0.1945\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2638 - accuracy: 0.1978\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2622 - accuracy: 0.2022\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2606 - accuracy: 0.2052\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2591 - accuracy: 0.2105\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2574 - accuracy: 0.2130\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2558 - accuracy: 0.2176\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2541 - accuracy: 0.2227\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2523 - accuracy: 0.2266\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2506 - accuracy: 0.2284\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2489 - accuracy: 0.2356\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2471 - accuracy: 0.2392\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2454 - accuracy: 0.2411\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2436 - accuracy: 0.2454\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2418 - accuracy: 0.2509\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2400 - accuracy: 0.2530\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2382 - accuracy: 0.2556\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2363 - accuracy: 0.2608\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2344 - accuracy: 0.2642\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2325 - accuracy: 0.2697\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2305 - accuracy: 0.2713\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2285 - accuracy: 0.2743\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2265 - accuracy: 0.2790\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2244 - accuracy: 0.2845\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2223 - accuracy: 0.2888\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2201 - accuracy: 0.2920\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2179 - accuracy: 0.2949\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2157 - accuracy: 0.3006\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2134 - accuracy: 0.3037\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2110 - accuracy: 0.3068\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2086 - accuracy: 0.3082\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2062 - accuracy: 0.3128\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2039 - accuracy: 0.3132\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2015 - accuracy: 0.3205\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1990 - accuracy: 0.3203\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1964 - accuracy: 0.3249\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1939 - accuracy: 0.3293\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1914 - accuracy: 0.3316\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1888 - accuracy: 0.3365\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1863 - accuracy: 0.3390\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1836 - accuracy: 0.3428\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1811 - accuracy: 0.3452\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1784 - accuracy: 0.3481\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1757 - accuracy: 0.3506\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1730 - accuracy: 0.3553\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1702 - accuracy: 0.3559\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1674 - accuracy: 0.3597\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1645 - accuracy: 0.3637\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1616 - accuracy: 0.3655\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1588 - accuracy: 0.3682\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1558 - accuracy: 0.3718\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1529 - accuracy: 0.3737\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1499 - accuracy: 0.3761\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1469 - accuracy: 0.3780\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1438 - accuracy: 0.3810\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1408 - accuracy: 0.3830\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1377 - accuracy: 0.3849\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1345 - accuracy: 0.3874\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1312 - accuracy: 0.3899\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1280 - accuracy: 0.3930\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1247 - accuracy: 0.3944\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1214 - accuracy: 0.3972\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1181 - accuracy: 0.3984\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1147 - accuracy: 0.4016\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1113 - accuracy: 0.4025\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1079 - accuracy: 0.4070\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1044 - accuracy: 0.4068\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1010 - accuracy: 0.4092\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0975 - accuracy: 0.4121\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0941 - accuracy: 0.4135\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0906 - accuracy: 0.4152\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0871 - accuracy: 0.4179\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0836 - accuracy: 0.4202\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0801 - accuracy: 0.4207\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0765 - accuracy: 0.4236\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0730 - accuracy: 0.4245\n",
            "Learning Rate: 9.34986628293961e-07  and Lambda: 3.6761553862633414e-07 and score: [2.070430278778076, 0.425555557012558]\n",
            "Counter: 3/10\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_53 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_53 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_54 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_55 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2929 - accuracy: 0.1141\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2420 - accuracy: 0.1281\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2332 - accuracy: 0.1322\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2336 - accuracy: 0.1340\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2289 - accuracy: 0.1341\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2313 - accuracy: 0.1332\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2277 - accuracy: 0.1329\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2294 - accuracy: 0.1385\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2272 - accuracy: 0.1328\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2259 - accuracy: 0.1372\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2280 - accuracy: 0.1340\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2241 - accuracy: 0.1376\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2263 - accuracy: 0.1355\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2266 - accuracy: 0.1353\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2234 - accuracy: 0.1392\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2258 - accuracy: 0.1375\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2233 - accuracy: 0.1380\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2236 - accuracy: 0.1386\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2232 - accuracy: 0.1394\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2247 - accuracy: 0.1375\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2238 - accuracy: 0.1387\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2234 - accuracy: 0.1369\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2259 - accuracy: 0.1362\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2234 - accuracy: 0.1408\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2232 - accuracy: 0.1394\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2245 - accuracy: 0.1366\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2237 - accuracy: 0.1395\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2224 - accuracy: 0.1409\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2254 - accuracy: 0.1368\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2231 - accuracy: 0.1388\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2155 - accuracy: 0.1370\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2191 - accuracy: 0.1393\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1943 - accuracy: 0.1494\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1657 - accuracy: 0.1609\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1595 - accuracy: 0.1642\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1582 - accuracy: 0.1663\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1555 - accuracy: 0.1696\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1585 - accuracy: 0.1677\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1575 - accuracy: 0.1678\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1537 - accuracy: 0.1647\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1476 - accuracy: 0.1677\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1445 - accuracy: 0.1692\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1463 - accuracy: 0.1676\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1413 - accuracy: 0.1726\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1467 - accuracy: 0.1708\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1331 - accuracy: 0.1728\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1321 - accuracy: 0.1749\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1274 - accuracy: 0.1753\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1298 - accuracy: 0.1732\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1275 - accuracy: 0.1761\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1260 - accuracy: 0.1783\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1248 - accuracy: 0.1764\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1330 - accuracy: 0.1751\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1279 - accuracy: 0.1742\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1226 - accuracy: 0.1774\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1293 - accuracy: 0.1762\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1283 - accuracy: 0.1757\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1236 - accuracy: 0.1782\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1231 - accuracy: 0.1775\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1183 - accuracy: 0.1798\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1247 - accuracy: 0.1765\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1190 - accuracy: 0.1785\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1231 - accuracy: 0.1771\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1205 - accuracy: 0.1785\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1136 - accuracy: 0.1799\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1215 - accuracy: 0.1785\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1170 - accuracy: 0.1812\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1142 - accuracy: 0.1823\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1187 - accuracy: 0.1787\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1173 - accuracy: 0.1773\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1205 - accuracy: 0.1786\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1176 - accuracy: 0.1794\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1163 - accuracy: 0.1804\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1144 - accuracy: 0.1801\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1129 - accuracy: 0.1822\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1180 - accuracy: 0.1766\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1164 - accuracy: 0.1791\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1151 - accuracy: 0.1794\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1165 - accuracy: 0.1815\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1119 - accuracy: 0.1816\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1202 - accuracy: 0.1793\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1181 - accuracy: 0.1783\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1135 - accuracy: 0.1803\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1142 - accuracy: 0.1807\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1153 - accuracy: 0.1819\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1099 - accuracy: 0.1815\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1164 - accuracy: 0.1807\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1196 - accuracy: 0.1783\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1159 - accuracy: 0.1791\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1148 - accuracy: 0.1780\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1150 - accuracy: 0.1815\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1139 - accuracy: 0.1826\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1196 - accuracy: 0.1788\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1161 - accuracy: 0.1793\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1160 - accuracy: 0.1803\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1150 - accuracy: 0.1795\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1162 - accuracy: 0.1793\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1126 - accuracy: 0.1807\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1157 - accuracy: 0.1794\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1100 - accuracy: 0.1827\n",
            "Learning Rate: 0.003521752935848459  and Lambda: 9.427863977089092e-06 and score: [2.0986733436584473, 0.18894444406032562]\n",
            "Counter: 4/10\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_56 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_56 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3240 - accuracy: 0.0976\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0989\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3032 - accuracy: 0.0978\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0995\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3031 - accuracy: 0.1006\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0993\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3031 - accuracy: 0.0980\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1025\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0986\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1016\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0982\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0997\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0978\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0991\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3031 - accuracy: 0.0981\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0996\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0982\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0989\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1009\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0978\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1006\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1014\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0987\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1004\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1005\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1006\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1010\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0978\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0992\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0984\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1013\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1002\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3028 - accuracy: 0.1010\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0993\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0990\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1011\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0976\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1015\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0988\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0992\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0985\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0981\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0989\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1002\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0987\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0993\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0998\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1011\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0982\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1002\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0985\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0971\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1006\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0986\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0984\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0984\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0994\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0987\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0947\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1001\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0970\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0994\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0992\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1006\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0971\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1006\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0995\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3031 - accuracy: 0.0978\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0998\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0995\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0995\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1014\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3031 - accuracy: 0.1004\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1003\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1009\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0983\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0993\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0980\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0990\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0962\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3028 - accuracy: 0.1001\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0963\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0989\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3031 - accuracy: 0.0988\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0998\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1006\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1007\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0986\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0993\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0993\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0993\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0988\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0998\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0974\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0965\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0989\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.0972\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.0987\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1008\n",
            "Learning Rate: 0.0039764364945453785  and Lambda: 5.7633189113574446e-06 and score: [2.3031225204467773, 0.10016666352748871]\n",
            "Counter: 5/10\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_59 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2797 - accuracy: 0.1529\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1836 - accuracy: 0.2976\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0160 - accuracy: 0.4272\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.8178 - accuracy: 0.5052\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.6471 - accuracy: 0.5548\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5151 - accuracy: 0.5908\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4161 - accuracy: 0.6127\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3396 - accuracy: 0.6287\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2816 - accuracy: 0.6422\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2342 - accuracy: 0.6519\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1941 - accuracy: 0.6619\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1624 - accuracy: 0.6686\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1331 - accuracy: 0.6734\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1087 - accuracy: 0.6806\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0871 - accuracy: 0.6851\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0651 - accuracy: 0.6912\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0462 - accuracy: 0.6967\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0290 - accuracy: 0.7018\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0131 - accuracy: 0.7061\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9969 - accuracy: 0.7081\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9827 - accuracy: 0.7116\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9676 - accuracy: 0.7176\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9543 - accuracy: 0.7200\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9407 - accuracy: 0.7255\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9265 - accuracy: 0.7284\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9164 - accuracy: 0.7302\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9031 - accuracy: 0.7347\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8930 - accuracy: 0.7372\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8807 - accuracy: 0.7412\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8697 - accuracy: 0.7455\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8608 - accuracy: 0.7484\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8502 - accuracy: 0.7507\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8386 - accuracy: 0.7556\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8297 - accuracy: 0.7565\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8211 - accuracy: 0.7587\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8123 - accuracy: 0.7609\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8027 - accuracy: 0.7655\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7944 - accuracy: 0.7660\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7859 - accuracy: 0.7698\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7769 - accuracy: 0.7715\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7694 - accuracy: 0.7745\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7623 - accuracy: 0.7768\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7541 - accuracy: 0.7789\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7476 - accuracy: 0.7811\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7408 - accuracy: 0.7815\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7338 - accuracy: 0.7826\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7274 - accuracy: 0.7854\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7203 - accuracy: 0.7880\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7165 - accuracy: 0.7895\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7090 - accuracy: 0.7915\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7013 - accuracy: 0.7946\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6966 - accuracy: 0.7955\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.7964\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.7988\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6815 - accuracy: 0.7999\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.8005\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6721 - accuracy: 0.8032\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6649 - accuracy: 0.8046\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6615 - accuracy: 0.8053\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6556 - accuracy: 0.8077\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6508 - accuracy: 0.8090\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6463 - accuracy: 0.8105\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6430 - accuracy: 0.8112\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.8149\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6352 - accuracy: 0.8133\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6291 - accuracy: 0.8156\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.8159\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6236 - accuracy: 0.8157\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6173 - accuracy: 0.8194\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6131 - accuracy: 0.8207\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6097 - accuracy: 0.8213\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6065 - accuracy: 0.8210\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6023 - accuracy: 0.8238\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6001 - accuracy: 0.8248\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.8247\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.8260\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5881 - accuracy: 0.8268\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5858 - accuracy: 0.8286\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5821 - accuracy: 0.8310\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5787 - accuracy: 0.8293\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5751 - accuracy: 0.8322\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5752 - accuracy: 0.8316\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.8338\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.8330\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5646 - accuracy: 0.8350\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5618 - accuracy: 0.8364\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5574 - accuracy: 0.8371\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5566 - accuracy: 0.8367\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5524 - accuracy: 0.8385\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5523 - accuracy: 0.8391\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.8390\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.8417\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.8418\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.8438\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.8430\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.8450\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.8440\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.8464\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.8475\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5249 - accuracy: 0.8466\n",
            "Learning Rate: 4.009732153420174e-05  and Lambda: 2.034664022387577e-06 and score: [0.6401745080947876, 0.8179444670677185]\n",
            "Counter: 6/10\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_62 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5850321519640576.0000 - accuracy: 0.0959\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5790563.5000 - accuracy: 0.0995\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5766672.0000 - accuracy: 0.1003\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5740745.0000 - accuracy: 0.0985\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5713219.5000 - accuracy: 0.0997\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5683880.0000 - accuracy: 0.0979\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5653380.5000 - accuracy: 0.1010\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5621244.5000 - accuracy: 0.0998\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5588423.0000 - accuracy: 0.1013\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5553579.5000 - accuracy: 0.1016\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5516796.5000 - accuracy: 0.0992\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5477882.5000 - accuracy: 0.0986\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5437054.0000 - accuracy: 0.1012\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5393614.0000 - accuracy: 0.1014\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5347867.5000 - accuracy: 0.0999\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5299337.5000 - accuracy: 0.1026\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5248363.0000 - accuracy: 0.1003\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5195883.5000 - accuracy: 0.1018\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5141755.5000 - accuracy: 0.0994\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5087376.5000 - accuracy: 0.0994\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 5033410.0000 - accuracy: 0.1003\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4981739.5000 - accuracy: 0.1010\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4932219.5000 - accuracy: 0.0967\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4886456.5000 - accuracy: 0.0998\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4846034.0000 - accuracy: 0.0997\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4809954.5000 - accuracy: 0.1004\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4779559.0000 - accuracy: 0.1005\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4754743.5000 - accuracy: 0.1017\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4734526.5000 - accuracy: 0.1008\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4718719.0000 - accuracy: 0.0971\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4707751.5000 - accuracy: 0.1027\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4699726.5000 - accuracy: 0.0984\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4693491.5000 - accuracy: 0.0998\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4689504.0000 - accuracy: 0.0975\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4686771.0000 - accuracy: 0.0973\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4684986.5000 - accuracy: 0.0975\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4683090.5000 - accuracy: 0.0998\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4681995.0000 - accuracy: 0.0996\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4680932.5000 - accuracy: 0.1003\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4679849.5000 - accuracy: 0.0996\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4679199.0000 - accuracy: 0.1027\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4677601.5000 - accuracy: 0.1015\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4676518.5000 - accuracy: 0.1013\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4675238.5000 - accuracy: 0.1030\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4673560.0000 - accuracy: 0.0989\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4671413.0000 - accuracy: 0.0968\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4669126.5000 - accuracy: 0.1021\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4666125.0000 - accuracy: 0.0998\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4662522.0000 - accuracy: 0.1004\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4658884.0000 - accuracy: 0.1010\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4653317.5000 - accuracy: 0.0987\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4647410.0000 - accuracy: 0.1047\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4640775.0000 - accuracy: 0.0975\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4631916.0000 - accuracy: 0.0995\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4622960.0000 - accuracy: 0.0996\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4611770.5000 - accuracy: 0.0994\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4599152.5000 - accuracy: 0.1011\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4585225.5000 - accuracy: 0.1011\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4567432.5000 - accuracy: 0.1009\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4548737.5000 - accuracy: 0.1040\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4527731.0000 - accuracy: 0.1019\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4502446.5000 - accuracy: 0.1021\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4473823.0000 - accuracy: 0.0999\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4439635.5000 - accuracy: 0.1013\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4400861.0000 - accuracy: 0.0990\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4356314.0000 - accuracy: 0.0976\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4304625.0000 - accuracy: 0.0982\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4245011.5000 - accuracy: 0.0989\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4177430.5000 - accuracy: 0.0983\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4101422.7500 - accuracy: 0.0985\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 4015226.0000 - accuracy: 0.0981\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3919522.0000 - accuracy: 0.0982\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3813024.2500 - accuracy: 0.1011\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3694905.2500 - accuracy: 0.1014\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3564411.0000 - accuracy: 0.1017\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3422817.0000 - accuracy: 0.0994\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3268912.5000 - accuracy: 0.1007\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3103024.7500 - accuracy: 0.0999\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2926376.0000 - accuracy: 0.0989\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2739524.7500 - accuracy: 0.1013\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2544272.0000 - accuracy: 0.0978\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2342116.5000 - accuracy: 0.1012\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2134721.5000 - accuracy: 0.1024\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1925923.2500 - accuracy: 0.0984\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1717867.8750 - accuracy: 0.0997\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1513543.2500 - accuracy: 0.1016\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1315168.5000 - accuracy: 0.0987\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1125575.0000 - accuracy: 0.1026\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 946982.4375 - accuracy: 0.0990\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 782758.0625 - accuracy: 0.1019\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 634555.3750 - accuracy: 0.1018\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 504162.1562 - accuracy: 0.1009\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 391668.0938 - accuracy: 0.1012\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1047242949525504.0000 - accuracy: 0.1024\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 244220064.0000 - accuracy: 0.1018\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 242422736.0000 - accuracy: 0.1005\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 240487392.0000 - accuracy: 0.0978\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 238322992.0000 - accuracy: 0.0983\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 235854176.0000 - accuracy: 0.1003\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 233016848.0000 - accuracy: 0.0991\n",
            "Learning Rate: 10422.350307053015  and Lambda: 5.58273546236563e-07 and score: [231454048.0, 0.10022222250699997]\n",
            "Counter: 7/10\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_65 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3166 - accuracy: 0.1074\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2966 - accuracy: 0.1264\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2890 - accuracy: 0.1426\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2813 - accuracy: 0.1599\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2729 - accuracy: 0.1775\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2645 - accuracy: 0.1979\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2554 - accuracy: 0.2168\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2457 - accuracy: 0.2379\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2352 - accuracy: 0.2595\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2239 - accuracy: 0.2777\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2118 - accuracy: 0.2980\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1987 - accuracy: 0.3121\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1848 - accuracy: 0.3340\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1702 - accuracy: 0.3478\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1548 - accuracy: 0.3600\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1390 - accuracy: 0.3757\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1217 - accuracy: 0.3888\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1042 - accuracy: 0.4001\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0861 - accuracy: 0.4122\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0674 - accuracy: 0.4191\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0486 - accuracy: 0.4314\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0290 - accuracy: 0.4374\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.0094 - accuracy: 0.4479\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.9897 - accuracy: 0.4530\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.9694 - accuracy: 0.4617\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.9486 - accuracy: 0.4723\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.9280 - accuracy: 0.4777\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.9073 - accuracy: 0.4860\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.8869 - accuracy: 0.4943\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.8665 - accuracy: 0.4975\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.8467 - accuracy: 0.5083\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.8270 - accuracy: 0.5129\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.8077 - accuracy: 0.5188\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.7886 - accuracy: 0.5265\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.7703 - accuracy: 0.5328\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.7522 - accuracy: 0.5384\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.7345 - accuracy: 0.5414\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.7171 - accuracy: 0.5489\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.7000 - accuracy: 0.5549\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.6833 - accuracy: 0.5600\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.6671 - accuracy: 0.5633\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.6513 - accuracy: 0.5684\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.6360 - accuracy: 0.5719\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.6208 - accuracy: 0.5754\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.6061 - accuracy: 0.5802\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5917 - accuracy: 0.5849\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5777 - accuracy: 0.5874\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5640 - accuracy: 0.5919\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5507 - accuracy: 0.5929\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5376 - accuracy: 0.5975\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5250 - accuracy: 0.6000\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5128 - accuracy: 0.6035\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5008 - accuracy: 0.6064\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4891 - accuracy: 0.6072\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4776 - accuracy: 0.6125\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4665 - accuracy: 0.6155\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4554 - accuracy: 0.6163\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4448 - accuracy: 0.6194\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4345 - accuracy: 0.6229\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4244 - accuracy: 0.6243\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4147 - accuracy: 0.6250\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4050 - accuracy: 0.6292\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3957 - accuracy: 0.6315\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3863 - accuracy: 0.6344\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3775 - accuracy: 0.6340\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3688 - accuracy: 0.6364\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3603 - accuracy: 0.6386\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3520 - accuracy: 0.6396\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3441 - accuracy: 0.6412\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3364 - accuracy: 0.6437\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3283 - accuracy: 0.6456\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3210 - accuracy: 0.6459\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3135 - accuracy: 0.6482\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3063 - accuracy: 0.6500\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2989 - accuracy: 0.6510\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2922 - accuracy: 0.6523\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2854 - accuracy: 0.6531\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2787 - accuracy: 0.6545\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2726 - accuracy: 0.6565\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2662 - accuracy: 0.6575\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2599 - accuracy: 0.6584\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2537 - accuracy: 0.6592\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2481 - accuracy: 0.6607\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2422 - accuracy: 0.6624\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2365 - accuracy: 0.6632\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2310 - accuracy: 0.6633\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2255 - accuracy: 0.6649\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2201 - accuracy: 0.6655\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2148 - accuracy: 0.6670\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2097 - accuracy: 0.6689\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2047 - accuracy: 0.6695\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1993 - accuracy: 0.6701\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1948 - accuracy: 0.6711\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1898 - accuracy: 0.6715\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1852 - accuracy: 0.6732\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1805 - accuracy: 0.6743\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1757 - accuracy: 0.6754\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1713 - accuracy: 0.6759\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1672 - accuracy: 0.6759\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1625 - accuracy: 0.6779\n",
            "Learning Rate: 4.639640793408314e-06  and Lambda: 4.62241289226046e-05 and score: [1.1641831398010254, 0.6730555295944214]\n",
            "Counter: 8/10\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_68 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_69 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_70 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1048 - accuracy: 0.2686\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4543 - accuracy: 0.5612\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2218 - accuracy: 0.6362\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1119 - accuracy: 0.6729\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0403 - accuracy: 0.6957\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9790 - accuracy: 0.7152\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9419 - accuracy: 0.7259\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9060 - accuracy: 0.7364\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8746 - accuracy: 0.7450\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8461 - accuracy: 0.7574\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8232 - accuracy: 0.7645\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8068 - accuracy: 0.7685\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7836 - accuracy: 0.7752\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7692 - accuracy: 0.7809\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7520 - accuracy: 0.7871\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7335 - accuracy: 0.7916\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7264 - accuracy: 0.7948\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7078 - accuracy: 0.8005\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6995 - accuracy: 0.8034\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.8065\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6727 - accuracy: 0.8103\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6582 - accuracy: 0.8166\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6537 - accuracy: 0.8167\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6440 - accuracy: 0.8195\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6345 - accuracy: 0.8228\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6192 - accuracy: 0.8270\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6172 - accuracy: 0.8277\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6067 - accuracy: 0.8308\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6071 - accuracy: 0.8307\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.8337\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.8370\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5790 - accuracy: 0.8400\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5725 - accuracy: 0.8416\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5687 - accuracy: 0.8422\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5625 - accuracy: 0.8445\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5557 - accuracy: 0.8471\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.8455\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.8507\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.8525\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.8522\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.8541\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.8571\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5160 - accuracy: 0.8566\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.8573\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5092 - accuracy: 0.8595\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5006 - accuracy: 0.8630\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4973 - accuracy: 0.8634\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4924 - accuracy: 0.8656\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4925 - accuracy: 0.8641\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.8671\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.8697\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4743 - accuracy: 0.8696\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.8717\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.8734\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.8735\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.8741\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.8766\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4499 - accuracy: 0.8773\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4522 - accuracy: 0.8773\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8787\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8806\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.8816\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4344 - accuracy: 0.8819\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.8805\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4262 - accuracy: 0.8854\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4208 - accuracy: 0.8860\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4209 - accuracy: 0.8865\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4214 - accuracy: 0.8840\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4135 - accuracy: 0.8893\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8877\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4080 - accuracy: 0.8900\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4041 - accuracy: 0.8910\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4057 - accuracy: 0.8885\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8926\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3922 - accuracy: 0.8950\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8949\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3952 - accuracy: 0.8932\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3866 - accuracy: 0.8976\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3844 - accuracy: 0.8973\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3845 - accuracy: 0.8962\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3819 - accuracy: 0.8969\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3758 - accuracy: 0.8999\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3769 - accuracy: 0.8990\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3758 - accuracy: 0.8995\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3739 - accuracy: 0.9001\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3716 - accuracy: 0.9005\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3676 - accuracy: 0.9015\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.9016\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.9025\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.9038\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3590 - accuracy: 0.9042\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3553 - accuracy: 0.9062\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.9069\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.9072\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.9086\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.9074\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.9092\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3401 - accuracy: 0.9103\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.9106\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3399 - accuracy: 0.9102\n",
            "Learning Rate: 0.00037642764833289  and Lambda: 0.0011593510702748047 and score: [0.6129623055458069, 0.8467222452163696]\n",
            "Counter: 9/10\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_71 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_71 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_72 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_73 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 8501539354684948480.0000 - accuracy: 0.0980\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3374590720.0000 - accuracy: 0.1011\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3341510656.0000 - accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3304446208.0000 - accuracy: 0.1012\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3265646080.0000 - accuracy: 0.1007\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3226814464.0000 - accuracy: 0.0984\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3189308928.0000 - accuracy: 0.1011\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3154109184.0000 - accuracy: 0.0988\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3121951232.0000 - accuracy: 0.1010\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3093335552.0000 - accuracy: 0.0984\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3068611328.0000 - accuracy: 0.0975\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3047940864.0000 - accuracy: 0.0982\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3031288320.0000 - accuracy: 0.0998\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3018352640.0000 - accuracy: 0.1005\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3008643072.0000 - accuracy: 0.1002\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 3001547264.0000 - accuracy: 0.0991\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2996470528.0000 - accuracy: 0.0999\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2992846080.0000 - accuracy: 0.1007\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2990238976.0000 - accuracy: 0.0992\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2988310016.0000 - accuracy: 0.1008\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2986864384.0000 - accuracy: 0.0998\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2985758976.0000 - accuracy: 0.1014\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2984903680.0000 - accuracy: 0.0992\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2984252416.0000 - accuracy: 0.1023\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2983766272.0000 - accuracy: 0.0987\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2983420160.0000 - accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2983182592.0000 - accuracy: 0.1001\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2982993920.0000 - accuracy: 0.1042\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2982860288.0000 - accuracy: 0.1005\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2982716928.0000 - accuracy: 0.0990\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2982565120.0000 - accuracy: 0.1009\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2982372352.0000 - accuracy: 0.1002\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2982151168.0000 - accuracy: 0.1007\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2981873920.0000 - accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2981546752.0000 - accuracy: 0.0995\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2981159168.0000 - accuracy: 0.1021\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2980684032.0000 - accuracy: 0.0998\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2980116224.0000 - accuracy: 0.0990\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2979448576.0000 - accuracy: 0.1013\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2978679296.0000 - accuracy: 0.0992\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2977754624.0000 - accuracy: 0.0995\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2976677632.0000 - accuracy: 0.0998\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2975403776.0000 - accuracy: 0.1009\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2973915392.0000 - accuracy: 0.1003\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2972152320.0000 - accuracy: 0.1010\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2970052864.0000 - accuracy: 0.1004\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2967545088.0000 - accuracy: 0.1015\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2964527360.0000 - accuracy: 0.1006\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2960916736.0000 - accuracy: 0.0966\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2956595456.0000 - accuracy: 0.1005\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2951440128.0000 - accuracy: 0.0993\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2945303552.0000 - accuracy: 0.1007\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2938030848.0000 - accuracy: 0.1019\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2929423872.0000 - accuracy: 0.0991\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2919264768.0000 - accuracy: 0.0976\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2907293440.0000 - accuracy: 0.0955\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2893208064.0000 - accuracy: 0.0984\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2876663296.0000 - accuracy: 0.1009\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2857320960.0000 - accuracy: 0.1012\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2834772224.0000 - accuracy: 0.0996\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2808628224.0000 - accuracy: 0.1018\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2778521088.0000 - accuracy: 0.1005\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2744097024.0000 - accuracy: 0.0997\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2705062912.0000 - accuracy: 0.0999\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2661187584.0000 - accuracy: 0.1011\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2612287488.0000 - accuracy: 0.0998\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2558226944.0000 - accuracy: 0.1004\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2498975488.0000 - accuracy: 0.0998\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2434586624.0000 - accuracy: 0.1021\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2365320704.0000 - accuracy: 0.1016\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2291686656.0000 - accuracy: 0.0992\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2214505472.0000 - accuracy: 0.0984\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2134825600.0000 - accuracy: 0.0996\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2053870208.0000 - accuracy: 0.1002\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1972777856.0000 - accuracy: 0.1005\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1892454528.0000 - accuracy: 0.1003\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1813414912.0000 - accuracy: 0.1001\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1735737856.0000 - accuracy: 0.0992\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1659145984.0000 - accuracy: 0.0997\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1583125120.0000 - accuracy: 0.0985\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1507132672.0000 - accuracy: 0.1000\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1430704000.0000 - accuracy: 0.1002\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1353532800.0000 - accuracy: 0.0986\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1275437952.0000 - accuracy: 0.0991\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1196361472.0000 - accuracy: 0.1004\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1116270592.0000 - accuracy: 0.0985\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1035196672.0000 - accuracy: 0.0982\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 953238656.0000 - accuracy: 0.1000\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 870633280.0000 - accuracy: 0.0995\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 787789952.0000 - accuracy: 0.1003\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 705326656.0000 - accuracy: 0.1020\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 624024640.0000 - accuracy: 0.1020\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 544769216.0000 - accuracy: 0.0998\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 468481792.0000 - accuracy: 0.0953\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 396172448.0000 - accuracy: 0.1019\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 328858304.0000 - accuracy: 0.0998\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 267561200.0000 - accuracy: 0.1009\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 213212992.0000 - accuracy: 0.1011\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 166511328.0000 - accuracy: 0.0971\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 127742336.0000 - accuracy: 0.0993\n",
            "Learning Rate: 118461.76377326158  and Lambda: 2.441387965855715e-06 and score: [2087643747713024.0, 0.10177777707576752]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkhDSzthsKqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b9bf30c-73e0-44d4-c95b-1e2509d724ee"
      },
      "source": [
        "# As we can see 4 and 5 model giving us good accuracy.             8: 3e-4, 1e-3, \n",
        "# We'll run one more time to finer learningRate and Lambda values\n",
        "for val in range(1,5):\n",
        "  epochs = 100\n",
        "  lr = math.pow(10,np.random.uniform(-5,-3))\n",
        "  Lambda = math.pow(10,np.random.uniform(-6,-2))\n",
        "  print(f\"Counter: {val}/{str(10)}\")\n",
        "  prepapreUpdatedModel(epochs,lr,Lambda,X_train,y_train,X_test,y_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter: 1/10\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_74 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_74 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_75 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_76 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1152 - accuracy: 0.2597\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4951 - accuracy: 0.5355\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2406 - accuracy: 0.6215\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1154 - accuracy: 0.6604\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0349 - accuracy: 0.6870\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9727 - accuracy: 0.7048\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9251 - accuracy: 0.7191\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8880 - accuracy: 0.7305\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8536 - accuracy: 0.7414\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8266 - accuracy: 0.7501\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8023 - accuracy: 0.7587\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7751 - accuracy: 0.7663\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7538 - accuracy: 0.7727\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7352 - accuracy: 0.7788\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7243 - accuracy: 0.7825\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7057 - accuracy: 0.7876\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.7943\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6735 - accuracy: 0.7986\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6613 - accuracy: 0.8010\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6472 - accuracy: 0.8060\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6445 - accuracy: 0.8056\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6239 - accuracy: 0.8134\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6133 - accuracy: 0.8170\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.8189\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.8221\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5858 - accuracy: 0.8229\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5753 - accuracy: 0.8301\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5601 - accuracy: 0.8315\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5597 - accuracy: 0.8330\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.8348\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.8372\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.8416\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.8431\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.8459\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.8470\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5006 - accuracy: 0.8494\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4940 - accuracy: 0.8520\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4923 - accuracy: 0.8530\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.8557\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4802 - accuracy: 0.8555\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4737 - accuracy: 0.8571\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.8613\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.8599\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.8641\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4562 - accuracy: 0.8629\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8687\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.8663\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4371 - accuracy: 0.8688\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4318 - accuracy: 0.8704\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4232 - accuracy: 0.8732\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4204 - accuracy: 0.8737\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4184 - accuracy: 0.8745\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4183 - accuracy: 0.8735\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4067 - accuracy: 0.8756\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4076 - accuracy: 0.8780\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4001 - accuracy: 0.8808\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3992 - accuracy: 0.8806\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3972 - accuracy: 0.8798\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3868 - accuracy: 0.8820\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3841 - accuracy: 0.8841\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3831 - accuracy: 0.8852\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3837 - accuracy: 0.8845\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8860\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3689 - accuracy: 0.8888\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8889\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8904\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3683 - accuracy: 0.8878\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3598 - accuracy: 0.8911\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8928\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8941\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8965\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3429 - accuracy: 0.8964\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8951\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.8968\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8986\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8985\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8992\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8997\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.9019\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.9031\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.9039\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3193 - accuracy: 0.9036\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3170 - accuracy: 0.9036\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.9047\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.9069\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.9075\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.9080\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.9062\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2994 - accuracy: 0.9100\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2970 - accuracy: 0.9108\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.9137\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2883 - accuracy: 0.9129\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.9128\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2869 - accuracy: 0.9130\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.9139\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.9162\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.9163\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.9168\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.9151\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.9177\n",
            "Learning Rate: 0.0002864614574565116  and Lambda: 1.3491155408465089e-05 and score: [0.6191192269325256, 0.843500018119812]\n",
            "Counter: 2/10\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_77 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_77 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_78 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_79 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2338 - accuracy: 0.2100\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.7156 - accuracy: 0.4862\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3767 - accuracy: 0.5960\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2305 - accuracy: 0.6399\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1399 - accuracy: 0.6667\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0759 - accuracy: 0.6844\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0287 - accuracy: 0.6967\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9816 - accuracy: 0.7147\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9453 - accuracy: 0.7240\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9072 - accuracy: 0.7366\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8819 - accuracy: 0.7439\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8579 - accuracy: 0.7520\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8306 - accuracy: 0.7612\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8164 - accuracy: 0.7641\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7920 - accuracy: 0.7730\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7778 - accuracy: 0.7746\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7653 - accuracy: 0.7809\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7476 - accuracy: 0.7860\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7342 - accuracy: 0.7906\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7207 - accuracy: 0.7947\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7097 - accuracy: 0.7994\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7035 - accuracy: 0.7995\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.8044\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6821 - accuracy: 0.8074\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6726 - accuracy: 0.8084\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6636 - accuracy: 0.8099\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6551 - accuracy: 0.8144\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6430 - accuracy: 0.8180\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6385 - accuracy: 0.8218\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6322 - accuracy: 0.8222\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6213 - accuracy: 0.8247\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6161 - accuracy: 0.8265\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6086 - accuracy: 0.8282\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6065 - accuracy: 0.8290\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.8336\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.8335\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5861 - accuracy: 0.8369\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5790 - accuracy: 0.8371\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5742 - accuracy: 0.8395\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.8433\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.8415\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5568 - accuracy: 0.8463\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5529 - accuracy: 0.8460\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.8463\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.8497\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.8518\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.8537\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.8521\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.8533\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.8584\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.8582\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5106 - accuracy: 0.8584\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5073 - accuracy: 0.8610\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.8606\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.8632\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.8646\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.8656\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4873 - accuracy: 0.8655\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.8659\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.8682\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.8700\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4733 - accuracy: 0.8695\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.8717\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.8730\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.8736\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4599 - accuracy: 0.8742\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4571 - accuracy: 0.8758\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4542 - accuracy: 0.8767\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8788\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4487 - accuracy: 0.8783\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.8799\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8806\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.8816\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4330 - accuracy: 0.8839\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.8832\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8838\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.8850\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4237 - accuracy: 0.8869\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.8860\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4202 - accuracy: 0.8866\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8884\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4147 - accuracy: 0.8890\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4101 - accuracy: 0.8894\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4129 - accuracy: 0.8893\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4095 - accuracy: 0.8899\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4060 - accuracy: 0.8911\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4017 - accuracy: 0.8927\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3997 - accuracy: 0.8938\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3974 - accuracy: 0.8947\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3935 - accuracy: 0.8952\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3941 - accuracy: 0.8953\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3905 - accuracy: 0.8948\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3888 - accuracy: 0.8962\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3856 - accuracy: 0.8979\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3858 - accuracy: 0.8982\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3817 - accuracy: 0.8991\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3769 - accuracy: 0.9000\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3796 - accuracy: 0.9009\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3769 - accuracy: 0.8983\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.9013\n",
            "Learning Rate: 0.00015796906475220318  and Lambda: 0.0007237903134788219 and score: [0.608612596988678, 0.843666672706604]\n",
            "Counter: 3/10\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_80 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_80 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_81 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_82 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.3447 - accuracy: 0.1346\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2884 - accuracy: 0.2377\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2133 - accuracy: 0.3435\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1102 - accuracy: 0.4137\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.9895 - accuracy: 0.4693\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.8659 - accuracy: 0.5195\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.7531 - accuracy: 0.5483\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.6591 - accuracy: 0.5704\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5794 - accuracy: 0.5903\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.5151 - accuracy: 0.6038\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4612 - accuracy: 0.6162\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4151 - accuracy: 0.6243\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3774 - accuracy: 0.6322\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3430 - accuracy: 0.6402\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3138 - accuracy: 0.6470\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2888 - accuracy: 0.6514\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2642 - accuracy: 0.6584\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2425 - accuracy: 0.6634\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2236 - accuracy: 0.6680\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2052 - accuracy: 0.6717\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1882 - accuracy: 0.6782\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1730 - accuracy: 0.6815\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1576 - accuracy: 0.6861\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1429 - accuracy: 0.6903\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1303 - accuracy: 0.6940\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1176 - accuracy: 0.6974\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1059 - accuracy: 0.7012\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0935 - accuracy: 0.7037\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0840 - accuracy: 0.7063\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0730 - accuracy: 0.7097\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0615 - accuracy: 0.7134\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0537 - accuracy: 0.7154\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0442 - accuracy: 0.7181\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0323 - accuracy: 0.7221\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0244 - accuracy: 0.7241\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0162 - accuracy: 0.7282\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0072 - accuracy: 0.7292\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9991 - accuracy: 0.7320\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9912 - accuracy: 0.7357\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9824 - accuracy: 0.7372\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9753 - accuracy: 0.7388\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9670 - accuracy: 0.7411\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9603 - accuracy: 0.7438\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9532 - accuracy: 0.7449\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9455 - accuracy: 0.7477\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9401 - accuracy: 0.7502\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9325 - accuracy: 0.7512\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9260 - accuracy: 0.7543\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9183 - accuracy: 0.7562\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9131 - accuracy: 0.7573\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9071 - accuracy: 0.7587\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9012 - accuracy: 0.7600\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8959 - accuracy: 0.7622\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8896 - accuracy: 0.7639\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8844 - accuracy: 0.7659\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8790 - accuracy: 0.7677\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8739 - accuracy: 0.7678\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8682 - accuracy: 0.7703\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8627 - accuracy: 0.7726\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8575 - accuracy: 0.7732\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8530 - accuracy: 0.7742\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8490 - accuracy: 0.7768\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8431 - accuracy: 0.7773\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8382 - accuracy: 0.7793\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8343 - accuracy: 0.7795\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8298 - accuracy: 0.7810\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8255 - accuracy: 0.7828\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8224 - accuracy: 0.7834\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8169 - accuracy: 0.7848\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8121 - accuracy: 0.7879\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8101 - accuracy: 0.7873\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8056 - accuracy: 0.7892\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8019 - accuracy: 0.7900\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7972 - accuracy: 0.7915\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7931 - accuracy: 0.7916\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7893 - accuracy: 0.7942\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7872 - accuracy: 0.7933\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7835 - accuracy: 0.7960\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7807 - accuracy: 0.7945\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7762 - accuracy: 0.7972\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7719 - accuracy: 0.7989\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7698 - accuracy: 0.7980\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7659 - accuracy: 0.7998\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7628 - accuracy: 0.8021\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7593 - accuracy: 0.8020\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7557 - accuracy: 0.8036\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7540 - accuracy: 0.8037\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7506 - accuracy: 0.8053\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7470 - accuracy: 0.8064\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7439 - accuracy: 0.8070\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7413 - accuracy: 0.8072\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7388 - accuracy: 0.8085\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7368 - accuracy: 0.8100\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7325 - accuracy: 0.8103\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7301 - accuracy: 0.8120\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7273 - accuracy: 0.8120\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7251 - accuracy: 0.8135\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7219 - accuracy: 0.8147\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7201 - accuracy: 0.8160\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7153 - accuracy: 0.8173\n",
            "Learning Rate: 2.627410656326471e-05  and Lambda: 0.002804781219417367 and score: [0.7879875898361206, 0.7986666560173035]\n",
            "Counter: 4/10\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_83 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_83 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_84 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_85 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.1998 - accuracy: 0.2307\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.7157 - accuracy: 0.4901\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3915 - accuracy: 0.5918\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2383 - accuracy: 0.6331\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1479 - accuracy: 0.6576\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0837 - accuracy: 0.6749\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0348 - accuracy: 0.6896\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9930 - accuracy: 0.7030\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9557 - accuracy: 0.7139\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9252 - accuracy: 0.7238\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8983 - accuracy: 0.7319\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8754 - accuracy: 0.7377\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8523 - accuracy: 0.7446\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8283 - accuracy: 0.7521\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8090 - accuracy: 0.7577\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7943 - accuracy: 0.7629\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7756 - accuracy: 0.7677\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7571 - accuracy: 0.7735\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7414 - accuracy: 0.7777\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7239 - accuracy: 0.7846\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7134 - accuracy: 0.7890\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6980 - accuracy: 0.7919\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.7959\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6730 - accuracy: 0.8018\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6658 - accuracy: 0.8023\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6536 - accuracy: 0.8056\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6395 - accuracy: 0.8112\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6313 - accuracy: 0.8150\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6220 - accuracy: 0.8164\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6167 - accuracy: 0.8187\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6063 - accuracy: 0.8208\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.8261\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.8270\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5835 - accuracy: 0.8291\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.8301\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.8339\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.8348\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5546 - accuracy: 0.8363\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5471 - accuracy: 0.8393\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.8419\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.8419\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5298 - accuracy: 0.8460\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5256 - accuracy: 0.8465\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5196 - accuracy: 0.8482\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.8496\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5102 - accuracy: 0.8509\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.8507\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4976 - accuracy: 0.8538\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4975 - accuracy: 0.8550\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4923 - accuracy: 0.8550\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.8561\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.8586\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.8609\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.8618\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.8639\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.8649\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4590 - accuracy: 0.8665\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4562 - accuracy: 0.8671\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.8681\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.8687\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.8676\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8714\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4382 - accuracy: 0.8712\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8727\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4326 - accuracy: 0.8745\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4289 - accuracy: 0.8756\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4266 - accuracy: 0.8757\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4223 - accuracy: 0.8773\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4201 - accuracy: 0.8780\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4161 - accuracy: 0.8769\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4148 - accuracy: 0.8798\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4084 - accuracy: 0.8813\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4038 - accuracy: 0.8827\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4040 - accuracy: 0.8833\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3994 - accuracy: 0.8834\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3960 - accuracy: 0.8849\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3954 - accuracy: 0.8854\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3918 - accuracy: 0.8858\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3910 - accuracy: 0.8856\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3871 - accuracy: 0.8869\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3863 - accuracy: 0.8881\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3803 - accuracy: 0.8905\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3810 - accuracy: 0.8897\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8926\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3715 - accuracy: 0.8920\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8927\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3671 - accuracy: 0.8941\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8910\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8954\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8954\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3598 - accuracy: 0.8953\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8956\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3556 - accuracy: 0.8965\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3536 - accuracy: 0.8972\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3510 - accuracy: 0.8995\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.9004\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8999\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.9007\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.9022\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.9036\n",
            "Learning Rate: 0.00013204229767284695  and Lambda: 0.0001031079856273735 and score: [0.5639558434486389, 0.8491111397743225]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y5LCyjsixtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepapreWeighteddModel(epochs,learningRate,lVal,X_train,y_train,X_test,y_test):\n",
        "  hidden_nodes = 256\n",
        "  output_nodes = 10\n",
        "  input_shape = X_train.shape[1]\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(hidden_nodes,input_shape = (input_shape,),kernel_initializer='uniform'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(hidden_nodes,kernel_initializer='uniform'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(output_nodes,kernel_regularizer=regularizers.l2(lVal)))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  sgd = optimizers.Adam(learning_rate=learningRate)\n",
        "  # optimizers.SGD(learning_rate=learningRate,momentum=0.9)\n",
        "  # complie model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "  #Model summary\n",
        "  model.summary()\n",
        "\n",
        "  #Fit model\n",
        "  model.fit(X_train,y_train,epochs=epochs,batch_size=100,verbose=True)\n",
        "  score = model.evaluate(X_test,y_test,verbose=False)\n",
        "  print(f'Learning Rate: {learningRate}  and Lambda: {lVal} and score: {score}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An6SAABhR7vj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5aba27b-4c20-4ff6-b391-d5e0ac3edaa6"
      },
      "source": [
        "# By looking at model performance, we choose LearningRate and Lambda as following.\n",
        "LearningRate = 1e-4\n",
        "Lambda = 1e-4\n",
        "epochs = 100\n",
        "weighted_model = prepapreWeighteddModel(epochs,LearningRate,Lambda,X_train,y_train,X_test,y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_89 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "activation_89 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_90 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_91 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 330,762\n",
            "Trainable params: 330,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 2.2394 - accuracy: 0.2180\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.8236 - accuracy: 0.4591\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.4855 - accuracy: 0.5681\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.3209 - accuracy: 0.6133\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.2250 - accuracy: 0.6373\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1576 - accuracy: 0.6565\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.1016 - accuracy: 0.6720\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0599 - accuracy: 0.6850\n",
            "Epoch 9/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 1.0241 - accuracy: 0.6939\n",
            "Epoch 10/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9934 - accuracy: 0.7039\n",
            "Epoch 11/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9634 - accuracy: 0.7141\n",
            "Epoch 12/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9410 - accuracy: 0.7198\n",
            "Epoch 13/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.9172 - accuracy: 0.7256\n",
            "Epoch 14/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8983 - accuracy: 0.7320\n",
            "Epoch 15/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8772 - accuracy: 0.7374\n",
            "Epoch 16/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8574 - accuracy: 0.7445\n",
            "Epoch 17/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8417 - accuracy: 0.7493\n",
            "Epoch 18/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8248 - accuracy: 0.7537\n",
            "Epoch 19/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.8087 - accuracy: 0.7580\n",
            "Epoch 20/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7944 - accuracy: 0.7622\n",
            "Epoch 21/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7814 - accuracy: 0.7666\n",
            "Epoch 22/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7686 - accuracy: 0.7721\n",
            "Epoch 23/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7545 - accuracy: 0.7756\n",
            "Epoch 24/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7427 - accuracy: 0.7780\n",
            "Epoch 25/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7312 - accuracy: 0.7816\n",
            "Epoch 26/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7205 - accuracy: 0.7846\n",
            "Epoch 27/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.7070 - accuracy: 0.7903\n",
            "Epoch 28/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6991 - accuracy: 0.7926\n",
            "Epoch 29/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.7946\n",
            "Epoch 30/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6790 - accuracy: 0.7969\n",
            "Epoch 31/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6701 - accuracy: 0.8017\n",
            "Epoch 32/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6645 - accuracy: 0.8039\n",
            "Epoch 33/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.8050\n",
            "Epoch 34/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6461 - accuracy: 0.8078\n",
            "Epoch 35/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6399 - accuracy: 0.8098\n",
            "Epoch 36/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6289 - accuracy: 0.8155\n",
            "Epoch 37/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6230 - accuracy: 0.8180\n",
            "Epoch 38/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6160 - accuracy: 0.8165\n",
            "Epoch 39/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6151 - accuracy: 0.8199\n",
            "Epoch 40/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.6047 - accuracy: 0.8217\n",
            "Epoch 41/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.8219\n",
            "Epoch 42/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.8253\n",
            "Epoch 43/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5857 - accuracy: 0.8287\n",
            "Epoch 44/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5805 - accuracy: 0.8287\n",
            "Epoch 45/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5766 - accuracy: 0.8311\n",
            "Epoch 46/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.8327\n",
            "Epoch 47/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.8343\n",
            "Epoch 48/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5604 - accuracy: 0.8356\n",
            "Epoch 49/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5552 - accuracy: 0.8364\n",
            "Epoch 50/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5503 - accuracy: 0.8385\n",
            "Epoch 51/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.8379\n",
            "Epoch 52/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.8430\n",
            "Epoch 53/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.8421\n",
            "Epoch 54/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.8445\n",
            "Epoch 55/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.8441\n",
            "Epoch 56/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.8466\n",
            "Epoch 57/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.8491\n",
            "Epoch 58/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.8501\n",
            "Epoch 59/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.8503\n",
            "Epoch 60/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.8512\n",
            "Epoch 61/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.8525\n",
            "Epoch 62/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.8518\n",
            "Epoch 63/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.5001 - accuracy: 0.8535\n",
            "Epoch 64/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4912 - accuracy: 0.8556\n",
            "Epoch 65/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4901 - accuracy: 0.8578\n",
            "Epoch 66/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.8573\n",
            "Epoch 67/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4824 - accuracy: 0.8579\n",
            "Epoch 68/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4791 - accuracy: 0.8603\n",
            "Epoch 69/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.8602\n",
            "Epoch 70/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4711 - accuracy: 0.8630\n",
            "Epoch 71/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4731 - accuracy: 0.8626\n",
            "Epoch 72/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4688 - accuracy: 0.8634\n",
            "Epoch 73/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.8651\n",
            "Epoch 74/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4599 - accuracy: 0.8658\n",
            "Epoch 75/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.8682\n",
            "Epoch 76/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.8675\n",
            "Epoch 77/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.8680\n",
            "Epoch 78/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4484 - accuracy: 0.8687\n",
            "Epoch 79/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.8696\n",
            "Epoch 80/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.8685\n",
            "Epoch 81/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8716\n",
            "Epoch 82/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8720\n",
            "Epoch 83/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4350 - accuracy: 0.8735\n",
            "Epoch 84/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4344 - accuracy: 0.8745\n",
            "Epoch 85/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4302 - accuracy: 0.8747\n",
            "Epoch 86/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4263 - accuracy: 0.8759\n",
            "Epoch 87/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4254 - accuracy: 0.8755\n",
            "Epoch 88/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4207 - accuracy: 0.8798\n",
            "Epoch 89/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4167 - accuracy: 0.8800\n",
            "Epoch 90/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4207 - accuracy: 0.8772\n",
            "Epoch 91/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4144 - accuracy: 0.8798\n",
            "Epoch 92/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4128 - accuracy: 0.8810\n",
            "Epoch 93/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4110 - accuracy: 0.8797\n",
            "Epoch 94/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4057 - accuracy: 0.8812\n",
            "Epoch 95/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4029 - accuracy: 0.8835\n",
            "Epoch 96/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8838\n",
            "Epoch 97/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8827\n",
            "Epoch 98/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3993 - accuracy: 0.8833\n",
            "Epoch 99/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8854\n",
            "Epoch 100/100\n",
            "420/420 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8855\n",
            "Learning Rate: 0.0001  and Lambda: 0.0001 and score: [0.599945068359375, 0.8359444737434387]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x09WP-kjTzrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# And We got our model with learning and Lambda values and accuracy of 83%\n",
        "# And weight is initialized with \"uniform\"."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZlbRb8e4HPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets' build model with BatchNormalization\n",
        "def prepapreBatchNormaldModel(epochs,learningRate,lVal,X_train,y_train,X_test,y_test):\n",
        "  hidden_nodes = 256\n",
        "  hidden_nodes_2 = 128\n",
        "  output_nodes = 10\n",
        "  input_shape = X_train.shape[1]\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(hidden_nodes,input_shape = (input_shape,),kernel_initializer='uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(hidden_nodes_2,kernel_initializer='uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(hidden_nodes_2,kernel_initializer='uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(output_nodes,kernel_regularizer=regularizers.l2(lVal)))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  sgd = optimizers.Adam(learning_rate=learningRate)\n",
        "  # SGD(learning_rate=learningRate,momentum=0.9)\n",
        "  # complie model\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "  #Model summary\n",
        "  model.summary()\n",
        "\n",
        "  #Fit model\n",
        "  history = model.fit(X_train,y_train,epochs=epochs,batch_size=100,verbose=True,validation_data=(X_test,y_test))\n",
        "  score = model.evaluate(X_test,y_test,verbose=False)\n",
        "  print(f'Learning Rate: {learningRate}  and Lambda: {lVal} and score: {score}')\n",
        "  return (model,history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIcr9gts2fwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c920b32-c802-4563-f1b8-9e404ca94e70"
      },
      "source": [
        "LearningRate = 1e-4\n",
        "Lambda = 1e-4\n",
        "epochs = 200\n",
        "model,history = prepapreBatchNormaldModel(epochs,LearningRate, Lambda,X_train,y_train,X_test,y_test)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 315,146\n",
            "Trainable params: 314,122\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 2.3899 - accuracy: 0.1434 - val_loss: 2.1245 - val_accuracy: 0.2631\n",
            "Epoch 2/200\n",
            "420/420 [==============================] - 4s 8ms/step - loss: 2.0095 - accuracy: 0.2791 - val_loss: 1.6423 - val_accuracy: 0.4806\n",
            "Epoch 3/200\n",
            "420/420 [==============================] - 4s 8ms/step - loss: 1.7244 - accuracy: 0.3989 - val_loss: 1.4220 - val_accuracy: 0.5708\n",
            "Epoch 4/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 1.5542 - accuracy: 0.4722 - val_loss: 1.2477 - val_accuracy: 0.6337\n",
            "Epoch 5/200\n",
            "420/420 [==============================] - 4s 8ms/step - loss: 1.4372 - accuracy: 0.5212 - val_loss: 1.2353 - val_accuracy: 0.6275\n",
            "Epoch 6/200\n",
            "420/420 [==============================] - 4s 8ms/step - loss: 1.3527 - accuracy: 0.5540 - val_loss: 1.2237 - val_accuracy: 0.6305\n",
            "Epoch 7/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 1.2934 - accuracy: 0.5770 - val_loss: 1.0543 - val_accuracy: 0.6808\n",
            "Epoch 8/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 1.2403 - accuracy: 0.5995 - val_loss: 1.0360 - val_accuracy: 0.6929\n",
            "Epoch 9/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 1.2007 - accuracy: 0.6140 - val_loss: 0.9679 - val_accuracy: 0.7171\n",
            "Epoch 10/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 1.1618 - accuracy: 0.6293 - val_loss: 0.9120 - val_accuracy: 0.7326\n",
            "Epoch 11/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 1.1327 - accuracy: 0.6380 - val_loss: 0.9306 - val_accuracy: 0.7195\n",
            "Epoch 12/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 1.0948 - accuracy: 0.6491 - val_loss: 0.9200 - val_accuracy: 0.7148\n",
            "Epoch 13/200\n",
            "420/420 [==============================] - 4s 8ms/step - loss: 1.0740 - accuracy: 0.6554 - val_loss: 0.8717 - val_accuracy: 0.7324\n",
            "Epoch 14/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 1.0497 - accuracy: 0.6648 - val_loss: 0.8674 - val_accuracy: 0.7364\n",
            "Epoch 15/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 1.0311 - accuracy: 0.6726 - val_loss: 0.8495 - val_accuracy: 0.7383\n",
            "Epoch 16/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 1.0079 - accuracy: 0.6818 - val_loss: 0.8180 - val_accuracy: 0.7622\n",
            "Epoch 17/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 1.0009 - accuracy: 0.6826 - val_loss: 0.9038 - val_accuracy: 0.7187\n",
            "Epoch 18/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.9789 - accuracy: 0.6899 - val_loss: 0.8879 - val_accuracy: 0.7132\n",
            "Epoch 19/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.9694 - accuracy: 0.6950 - val_loss: 0.8102 - val_accuracy: 0.7510\n",
            "Epoch 20/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.9603 - accuracy: 0.6965 - val_loss: 0.7241 - val_accuracy: 0.7872\n",
            "Epoch 21/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.9476 - accuracy: 0.7021 - val_loss: 0.7618 - val_accuracy: 0.7632\n",
            "Epoch 22/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.9327 - accuracy: 0.7063 - val_loss: 0.7568 - val_accuracy: 0.7698\n",
            "Epoch 23/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.9173 - accuracy: 0.7104 - val_loss: 0.8799 - val_accuracy: 0.7300\n",
            "Epoch 24/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.9069 - accuracy: 0.7120 - val_loss: 0.7342 - val_accuracy: 0.7805\n",
            "Epoch 25/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.9008 - accuracy: 0.7164 - val_loss: 0.7334 - val_accuracy: 0.7778\n",
            "Epoch 26/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.8808 - accuracy: 0.7242 - val_loss: 0.7230 - val_accuracy: 0.7803\n",
            "Epoch 27/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8844 - accuracy: 0.7213 - val_loss: 0.7201 - val_accuracy: 0.7848\n",
            "Epoch 28/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8668 - accuracy: 0.7263 - val_loss: 0.6832 - val_accuracy: 0.7933\n",
            "Epoch 29/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8608 - accuracy: 0.7292 - val_loss: 0.6987 - val_accuracy: 0.7911\n",
            "Epoch 30/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8555 - accuracy: 0.7294 - val_loss: 0.7708 - val_accuracy: 0.7559\n",
            "Epoch 31/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8512 - accuracy: 0.7329 - val_loss: 0.6883 - val_accuracy: 0.7902\n",
            "Epoch 32/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8470 - accuracy: 0.7343 - val_loss: 0.7165 - val_accuracy: 0.7782\n",
            "Epoch 33/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8360 - accuracy: 0.7358 - val_loss: 0.7410 - val_accuracy: 0.7659\n",
            "Epoch 34/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8313 - accuracy: 0.7360 - val_loss: 0.6855 - val_accuracy: 0.7932\n",
            "Epoch 35/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8329 - accuracy: 0.7405 - val_loss: 0.6560 - val_accuracy: 0.8015\n",
            "Epoch 36/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8156 - accuracy: 0.7450 - val_loss: 0.7099 - val_accuracy: 0.7776\n",
            "Epoch 37/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.8100 - accuracy: 0.7449 - val_loss: 0.7160 - val_accuracy: 0.7789\n",
            "Epoch 38/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.8097 - accuracy: 0.7451 - val_loss: 0.6527 - val_accuracy: 0.8024\n",
            "Epoch 39/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7999 - accuracy: 0.7483 - val_loss: 0.6395 - val_accuracy: 0.8099\n",
            "Epoch 40/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7958 - accuracy: 0.7509 - val_loss: 0.6590 - val_accuracy: 0.7992\n",
            "Epoch 41/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7958 - accuracy: 0.7532 - val_loss: 0.6622 - val_accuracy: 0.7988\n",
            "Epoch 42/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7985 - accuracy: 0.7497 - val_loss: 0.7102 - val_accuracy: 0.7750\n",
            "Epoch 43/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7920 - accuracy: 0.7519 - val_loss: 0.6734 - val_accuracy: 0.7943\n",
            "Epoch 44/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7733 - accuracy: 0.7575 - val_loss: 0.6763 - val_accuracy: 0.7901\n",
            "Epoch 45/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7714 - accuracy: 0.7589 - val_loss: 0.6997 - val_accuracy: 0.7891\n",
            "Epoch 46/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7648 - accuracy: 0.7602 - val_loss: 0.6781 - val_accuracy: 0.7935\n",
            "Epoch 47/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7671 - accuracy: 0.7607 - val_loss: 0.7310 - val_accuracy: 0.7657\n",
            "Epoch 48/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7654 - accuracy: 0.7587 - val_loss: 0.6610 - val_accuracy: 0.7981\n",
            "Epoch 49/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7651 - accuracy: 0.7599 - val_loss: 0.6831 - val_accuracy: 0.7862\n",
            "Epoch 50/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7578 - accuracy: 0.7627 - val_loss: 0.7298 - val_accuracy: 0.7744\n",
            "Epoch 51/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7521 - accuracy: 0.7651 - val_loss: 0.6990 - val_accuracy: 0.7864\n",
            "Epoch 52/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7471 - accuracy: 0.7653 - val_loss: 0.7228 - val_accuracy: 0.7851\n",
            "Epoch 53/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7516 - accuracy: 0.7646 - val_loss: 0.5968 - val_accuracy: 0.8209\n",
            "Epoch 54/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7478 - accuracy: 0.7659 - val_loss: 0.6691 - val_accuracy: 0.7944\n",
            "Epoch 55/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7428 - accuracy: 0.7674 - val_loss: 0.5975 - val_accuracy: 0.8226\n",
            "Epoch 56/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7322 - accuracy: 0.7688 - val_loss: 0.5730 - val_accuracy: 0.8245\n",
            "Epoch 57/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7347 - accuracy: 0.7696 - val_loss: 0.6624 - val_accuracy: 0.7978\n",
            "Epoch 58/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7338 - accuracy: 0.7703 - val_loss: 0.6316 - val_accuracy: 0.8063\n",
            "Epoch 59/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7325 - accuracy: 0.7700 - val_loss: 0.7076 - val_accuracy: 0.7789\n",
            "Epoch 60/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7265 - accuracy: 0.7739 - val_loss: 0.5799 - val_accuracy: 0.8255\n",
            "Epoch 61/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7259 - accuracy: 0.7730 - val_loss: 0.6095 - val_accuracy: 0.8167\n",
            "Epoch 62/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.7226 - accuracy: 0.7735 - val_loss: 0.5964 - val_accuracy: 0.8228\n",
            "Epoch 63/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7237 - accuracy: 0.7739 - val_loss: 0.6259 - val_accuracy: 0.8132\n",
            "Epoch 64/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7147 - accuracy: 0.7750 - val_loss: 0.6044 - val_accuracy: 0.8213\n",
            "Epoch 65/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7108 - accuracy: 0.7787 - val_loss: 0.6444 - val_accuracy: 0.7998\n",
            "Epoch 66/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7135 - accuracy: 0.7753 - val_loss: 0.6304 - val_accuracy: 0.8106\n",
            "Epoch 67/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7162 - accuracy: 0.7753 - val_loss: 0.6397 - val_accuracy: 0.7993\n",
            "Epoch 68/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7136 - accuracy: 0.7753 - val_loss: 0.6789 - val_accuracy: 0.7925\n",
            "Epoch 69/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7081 - accuracy: 0.7770 - val_loss: 0.6415 - val_accuracy: 0.8024\n",
            "Epoch 70/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.7035 - accuracy: 0.7808 - val_loss: 0.6191 - val_accuracy: 0.8069\n",
            "Epoch 71/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6988 - accuracy: 0.7806 - val_loss: 0.5817 - val_accuracy: 0.8236\n",
            "Epoch 72/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6976 - accuracy: 0.7796 - val_loss: 0.5940 - val_accuracy: 0.8239\n",
            "Epoch 73/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.7022 - accuracy: 0.7805 - val_loss: 0.5878 - val_accuracy: 0.8335\n",
            "Epoch 74/200\n",
            "420/420 [==============================] - 4s 10ms/step - loss: 0.6991 - accuracy: 0.7814 - val_loss: 0.6204 - val_accuracy: 0.8093\n",
            "Epoch 75/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6941 - accuracy: 0.7803 - val_loss: 0.6293 - val_accuracy: 0.8065\n",
            "Epoch 76/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6944 - accuracy: 0.7836 - val_loss: 0.5970 - val_accuracy: 0.8178\n",
            "Epoch 77/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6932 - accuracy: 0.7836 - val_loss: 0.5657 - val_accuracy: 0.8302\n",
            "Epoch 78/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6902 - accuracy: 0.7848 - val_loss: 0.5946 - val_accuracy: 0.8149\n",
            "Epoch 79/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6877 - accuracy: 0.7823 - val_loss: 0.5558 - val_accuracy: 0.8317\n",
            "Epoch 80/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6883 - accuracy: 0.7826 - val_loss: 0.6630 - val_accuracy: 0.7963\n",
            "Epoch 81/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6875 - accuracy: 0.7846 - val_loss: 0.6234 - val_accuracy: 0.8115\n",
            "Epoch 82/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6860 - accuracy: 0.7853 - val_loss: 0.5821 - val_accuracy: 0.8231\n",
            "Epoch 83/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6800 - accuracy: 0.7856 - val_loss: 0.6521 - val_accuracy: 0.7969\n",
            "Epoch 84/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6827 - accuracy: 0.7832 - val_loss: 0.5696 - val_accuracy: 0.8235\n",
            "Epoch 85/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6786 - accuracy: 0.7860 - val_loss: 0.5439 - val_accuracy: 0.8335\n",
            "Epoch 86/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6826 - accuracy: 0.7853 - val_loss: 0.9211 - val_accuracy: 0.7206\n",
            "Epoch 87/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6715 - accuracy: 0.7902 - val_loss: 0.6143 - val_accuracy: 0.8161\n",
            "Epoch 88/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6765 - accuracy: 0.7880 - val_loss: 0.7896 - val_accuracy: 0.7538\n",
            "Epoch 89/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6735 - accuracy: 0.7881 - val_loss: 0.6091 - val_accuracy: 0.8102\n",
            "Epoch 90/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6714 - accuracy: 0.7888 - val_loss: 0.5653 - val_accuracy: 0.8297\n",
            "Epoch 91/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6697 - accuracy: 0.7888 - val_loss: 0.5757 - val_accuracy: 0.8273\n",
            "Epoch 92/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6686 - accuracy: 0.7918 - val_loss: 0.5939 - val_accuracy: 0.8138\n",
            "Epoch 93/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6697 - accuracy: 0.7885 - val_loss: 0.5951 - val_accuracy: 0.8157\n",
            "Epoch 94/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6656 - accuracy: 0.7906 - val_loss: 0.5512 - val_accuracy: 0.8328\n",
            "Epoch 95/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6633 - accuracy: 0.7898 - val_loss: 0.5541 - val_accuracy: 0.8350\n",
            "Epoch 96/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6633 - accuracy: 0.7905 - val_loss: 0.6361 - val_accuracy: 0.7968\n",
            "Epoch 97/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6681 - accuracy: 0.7903 - val_loss: 0.5461 - val_accuracy: 0.8349\n",
            "Epoch 98/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6685 - accuracy: 0.7880 - val_loss: 0.5674 - val_accuracy: 0.8242\n",
            "Epoch 99/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6647 - accuracy: 0.7904 - val_loss: 0.6095 - val_accuracy: 0.8122\n",
            "Epoch 100/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6548 - accuracy: 0.7931 - val_loss: 0.5930 - val_accuracy: 0.8235\n",
            "Epoch 101/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6623 - accuracy: 0.7922 - val_loss: 0.6120 - val_accuracy: 0.8119\n",
            "Epoch 102/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6557 - accuracy: 0.7939 - val_loss: 0.5745 - val_accuracy: 0.8278\n",
            "Epoch 103/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6558 - accuracy: 0.7938 - val_loss: 0.5510 - val_accuracy: 0.8364\n",
            "Epoch 104/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6630 - accuracy: 0.7914 - val_loss: 0.6053 - val_accuracy: 0.8115\n",
            "Epoch 105/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6528 - accuracy: 0.7945 - val_loss: 0.6001 - val_accuracy: 0.8166\n",
            "Epoch 106/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6590 - accuracy: 0.7910 - val_loss: 0.7083 - val_accuracy: 0.7769\n",
            "Epoch 107/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6564 - accuracy: 0.7929 - val_loss: 0.5620 - val_accuracy: 0.8283\n",
            "Epoch 108/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6499 - accuracy: 0.7946 - val_loss: 0.6061 - val_accuracy: 0.8138\n",
            "Epoch 109/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.7959 - val_loss: 0.5757 - val_accuracy: 0.8227\n",
            "Epoch 110/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6506 - accuracy: 0.7957 - val_loss: 0.6294 - val_accuracy: 0.8093\n",
            "Epoch 111/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6565 - accuracy: 0.7928 - val_loss: 0.6219 - val_accuracy: 0.8052\n",
            "Epoch 112/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6479 - accuracy: 0.7935 - val_loss: 0.5348 - val_accuracy: 0.8387\n",
            "Epoch 113/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6439 - accuracy: 0.7987 - val_loss: 0.6078 - val_accuracy: 0.8142\n",
            "Epoch 114/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6409 - accuracy: 0.7993 - val_loss: 0.5382 - val_accuracy: 0.8370\n",
            "Epoch 115/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6464 - accuracy: 0.7973 - val_loss: 0.6092 - val_accuracy: 0.8185\n",
            "Epoch 116/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6497 - accuracy: 0.7964 - val_loss: 0.5859 - val_accuracy: 0.8160\n",
            "Epoch 117/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6447 - accuracy: 0.7977 - val_loss: 0.5403 - val_accuracy: 0.8378\n",
            "Epoch 118/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6425 - accuracy: 0.7978 - val_loss: 0.5535 - val_accuracy: 0.8340\n",
            "Epoch 119/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6466 - accuracy: 0.7956 - val_loss: 0.5749 - val_accuracy: 0.8205\n",
            "Epoch 120/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6394 - accuracy: 0.7982 - val_loss: 0.5520 - val_accuracy: 0.8310\n",
            "Epoch 121/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6420 - accuracy: 0.7993 - val_loss: 0.5546 - val_accuracy: 0.8342\n",
            "Epoch 122/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6464 - accuracy: 0.7975 - val_loss: 0.6154 - val_accuracy: 0.8131\n",
            "Epoch 123/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6404 - accuracy: 0.8000 - val_loss: 0.5827 - val_accuracy: 0.8229\n",
            "Epoch 124/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6454 - accuracy: 0.7954 - val_loss: 0.5640 - val_accuracy: 0.8282\n",
            "Epoch 125/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6451 - accuracy: 0.7990 - val_loss: 0.5639 - val_accuracy: 0.8252\n",
            "Epoch 126/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6358 - accuracy: 0.8002 - val_loss: 0.6210 - val_accuracy: 0.8061\n",
            "Epoch 127/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6353 - accuracy: 0.8011 - val_loss: 0.5853 - val_accuracy: 0.8209\n",
            "Epoch 128/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6396 - accuracy: 0.7976 - val_loss: 0.5649 - val_accuracy: 0.8283\n",
            "Epoch 129/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6317 - accuracy: 0.8007 - val_loss: 0.5552 - val_accuracy: 0.8366\n",
            "Epoch 130/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6357 - accuracy: 0.7992 - val_loss: 0.5872 - val_accuracy: 0.8201\n",
            "Epoch 131/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6341 - accuracy: 0.8000 - val_loss: 0.5647 - val_accuracy: 0.8292\n",
            "Epoch 132/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6371 - accuracy: 0.8010 - val_loss: 0.5550 - val_accuracy: 0.8306\n",
            "Epoch 133/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6349 - accuracy: 0.8007 - val_loss: 0.6057 - val_accuracy: 0.8119\n",
            "Epoch 134/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6316 - accuracy: 0.7987 - val_loss: 0.5284 - val_accuracy: 0.8414\n",
            "Epoch 135/200\n",
            "420/420 [==============================] - 4s 8ms/step - loss: 0.6333 - accuracy: 0.7996 - val_loss: 0.5643 - val_accuracy: 0.8294\n",
            "Epoch 136/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6388 - accuracy: 0.7987 - val_loss: 0.5560 - val_accuracy: 0.8277\n",
            "Epoch 137/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6340 - accuracy: 0.7986 - val_loss: 0.6008 - val_accuracy: 0.8109\n",
            "Epoch 138/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6273 - accuracy: 0.8030 - val_loss: 0.5369 - val_accuracy: 0.8341\n",
            "Epoch 139/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6279 - accuracy: 0.8016 - val_loss: 0.5422 - val_accuracy: 0.8333\n",
            "Epoch 140/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6340 - accuracy: 0.7987 - val_loss: 0.5673 - val_accuracy: 0.8236\n",
            "Epoch 141/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6262 - accuracy: 0.8041 - val_loss: 0.5513 - val_accuracy: 0.8322\n",
            "Epoch 142/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6242 - accuracy: 0.8025 - val_loss: 0.5150 - val_accuracy: 0.8406\n",
            "Epoch 143/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6285 - accuracy: 0.8005 - val_loss: 0.5391 - val_accuracy: 0.8338\n",
            "Epoch 144/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6241 - accuracy: 0.8040 - val_loss: 0.5340 - val_accuracy: 0.8337\n",
            "Epoch 145/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6272 - accuracy: 0.8030 - val_loss: 0.5262 - val_accuracy: 0.8422\n",
            "Epoch 146/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6227 - accuracy: 0.8066 - val_loss: 0.5476 - val_accuracy: 0.8317\n",
            "Epoch 147/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6268 - accuracy: 0.8031 - val_loss: 0.5522 - val_accuracy: 0.8289\n",
            "Epoch 148/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6160 - accuracy: 0.8054 - val_loss: 0.5300 - val_accuracy: 0.8392\n",
            "Epoch 149/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6235 - accuracy: 0.8048 - val_loss: 0.5212 - val_accuracy: 0.8402\n",
            "Epoch 150/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6258 - accuracy: 0.8036 - val_loss: 0.5399 - val_accuracy: 0.8357\n",
            "Epoch 151/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6171 - accuracy: 0.8057 - val_loss: 0.5243 - val_accuracy: 0.8382\n",
            "Epoch 152/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6235 - accuracy: 0.8041 - val_loss: 0.5230 - val_accuracy: 0.8386\n",
            "Epoch 153/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6174 - accuracy: 0.8045 - val_loss: 0.5510 - val_accuracy: 0.8321\n",
            "Epoch 154/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6199 - accuracy: 0.8044 - val_loss: 0.5411 - val_accuracy: 0.8334\n",
            "Epoch 155/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6186 - accuracy: 0.8064 - val_loss: 0.5566 - val_accuracy: 0.8254\n",
            "Epoch 156/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6214 - accuracy: 0.8046 - val_loss: 0.5461 - val_accuracy: 0.8334\n",
            "Epoch 157/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6172 - accuracy: 0.8035 - val_loss: 0.5286 - val_accuracy: 0.8365\n",
            "Epoch 158/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6174 - accuracy: 0.8051 - val_loss: 0.5602 - val_accuracy: 0.8234\n",
            "Epoch 159/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6169 - accuracy: 0.8061 - val_loss: 0.5266 - val_accuracy: 0.8411\n",
            "Epoch 160/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6104 - accuracy: 0.8087 - val_loss: 0.5582 - val_accuracy: 0.8299\n",
            "Epoch 161/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6147 - accuracy: 0.8078 - val_loss: 0.5791 - val_accuracy: 0.8221\n",
            "Epoch 162/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6194 - accuracy: 0.8025 - val_loss: 0.5960 - val_accuracy: 0.8132\n",
            "Epoch 163/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6192 - accuracy: 0.8041 - val_loss: 0.5651 - val_accuracy: 0.8267\n",
            "Epoch 164/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6107 - accuracy: 0.8060 - val_loss: 0.5177 - val_accuracy: 0.8413\n",
            "Epoch 165/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6082 - accuracy: 0.8088 - val_loss: 0.5365 - val_accuracy: 0.8377\n",
            "Epoch 166/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6146 - accuracy: 0.8062 - val_loss: 0.5828 - val_accuracy: 0.8133\n",
            "Epoch 167/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6127 - accuracy: 0.8060 - val_loss: 0.5476 - val_accuracy: 0.8291\n",
            "Epoch 168/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6096 - accuracy: 0.8095 - val_loss: 0.5684 - val_accuracy: 0.8263\n",
            "Epoch 169/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6162 - accuracy: 0.8066 - val_loss: 0.5325 - val_accuracy: 0.8375\n",
            "Epoch 170/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6130 - accuracy: 0.8060 - val_loss: 0.6092 - val_accuracy: 0.8107\n",
            "Epoch 171/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6098 - accuracy: 0.8078 - val_loss: 0.5335 - val_accuracy: 0.8373\n",
            "Epoch 172/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6096 - accuracy: 0.8087 - val_loss: 0.5270 - val_accuracy: 0.8397\n",
            "Epoch 173/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6064 - accuracy: 0.8087 - val_loss: 0.5509 - val_accuracy: 0.8303\n",
            "Epoch 174/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6191 - accuracy: 0.8046 - val_loss: 0.5419 - val_accuracy: 0.8297\n",
            "Epoch 175/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6075 - accuracy: 0.8104 - val_loss: 0.5489 - val_accuracy: 0.8316\n",
            "Epoch 176/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6089 - accuracy: 0.8075 - val_loss: 0.5315 - val_accuracy: 0.8348\n",
            "Epoch 177/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6130 - accuracy: 0.8061 - val_loss: 0.5282 - val_accuracy: 0.8397\n",
            "Epoch 178/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6076 - accuracy: 0.8100 - val_loss: 0.5410 - val_accuracy: 0.8337\n",
            "Epoch 179/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6024 - accuracy: 0.8092 - val_loss: 0.5330 - val_accuracy: 0.8382\n",
            "Epoch 180/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6089 - accuracy: 0.8089 - val_loss: 0.5072 - val_accuracy: 0.8442\n",
            "Epoch 181/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.5994 - accuracy: 0.8103 - val_loss: 0.5126 - val_accuracy: 0.8464\n",
            "Epoch 182/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6100 - accuracy: 0.8084 - val_loss: 0.5330 - val_accuracy: 0.8389\n",
            "Epoch 183/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6012 - accuracy: 0.8098 - val_loss: 0.5893 - val_accuracy: 0.8204\n",
            "Epoch 184/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6076 - accuracy: 0.8090 - val_loss: 0.5389 - val_accuracy: 0.8380\n",
            "Epoch 185/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6029 - accuracy: 0.8092 - val_loss: 0.4859 - val_accuracy: 0.8557\n",
            "Epoch 186/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6027 - accuracy: 0.8101 - val_loss: 0.5152 - val_accuracy: 0.8444\n",
            "Epoch 187/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6001 - accuracy: 0.8094 - val_loss: 0.5423 - val_accuracy: 0.8349\n",
            "Epoch 188/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6039 - accuracy: 0.8096 - val_loss: 0.5474 - val_accuracy: 0.8324\n",
            "Epoch 189/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6002 - accuracy: 0.8098 - val_loss: 0.6137 - val_accuracy: 0.8092\n",
            "Epoch 190/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.5998 - accuracy: 0.8128 - val_loss: 0.5306 - val_accuracy: 0.8382\n",
            "Epoch 191/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6000 - accuracy: 0.8093 - val_loss: 0.5298 - val_accuracy: 0.8407\n",
            "Epoch 192/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.5955 - accuracy: 0.8144 - val_loss: 0.5209 - val_accuracy: 0.8397\n",
            "Epoch 193/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.5981 - accuracy: 0.8109 - val_loss: 0.5299 - val_accuracy: 0.8383\n",
            "Epoch 194/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6033 - accuracy: 0.8094 - val_loss: 0.5441 - val_accuracy: 0.8321\n",
            "Epoch 195/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.6045 - accuracy: 0.8102 - val_loss: 0.5575 - val_accuracy: 0.8242\n",
            "Epoch 196/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6001 - accuracy: 0.8124 - val_loss: 0.5657 - val_accuracy: 0.8250\n",
            "Epoch 197/200\n",
            "420/420 [==============================] - 3s 8ms/step - loss: 0.5947 - accuracy: 0.8127 - val_loss: 0.5787 - val_accuracy: 0.8192\n",
            "Epoch 198/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.6024 - accuracy: 0.8100 - val_loss: 0.5125 - val_accuracy: 0.8442\n",
            "Epoch 199/200\n",
            "420/420 [==============================] - 4s 9ms/step - loss: 0.5987 - accuracy: 0.8126 - val_loss: 0.4992 - val_accuracy: 0.8473\n",
            "Epoch 200/200\n",
            "420/420 [==============================] - 3s 7ms/step - loss: 0.6024 - accuracy: 0.8128 - val_loss: 0.5582 - val_accuracy: 0.8314\n",
            "Learning Rate: 0.0001  and Lambda: 0.0001 and score: [0.558197021484375, 0.8313888907432556]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUa1qXrRQ8WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model weights and model as well.\n",
        "model.save('P1_model.h5')\n",
        "model.save_weights('P1_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Qwk4DQOvST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b595e302-81f0-408e-ddfd-951f44c742be"
      },
      "source": [
        "# By seeing the baove result, we can say model is not overfitting.\n",
        "history.history.keys()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOXJLQeGOBL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "5e085f65-649f-4321-ae49-4e1327bff068"
      },
      "source": [
        "fig,ax = plt.subplots(1,2)\n",
        "ax[0].set_title('Accuracy')\n",
        "ax[0].plot(history.history['accuracy'],label='train')\n",
        "ax[0].plot(history.history['val_accuracy'],label='test')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].set_title('Loss')\n",
        "ax[1].plot(history.history['loss'],label='train')\n",
        "ax[1].plot(history.history['val_loss'],label='test')\n",
        "ax[1].legend()\n",
        "# By checking the accuracy and loss plots, suggest that the model has good fit on the problem."
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f52f02cada0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pPtzGBD3I3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's check classification report and multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix,confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3inTte_D-vVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classificationReport(y_true,y_pred):\n",
        "    target_names = [f\"Class {i}\" for i in range(10) ]\n",
        "    print(classification_report(y_true,y_pred,target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anxa-UOd8d56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEfB1qvD_XYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "a1f6976f-cdfb-4f2a-a914-bd6ac1c1bdd5"
      },
      "source": [
        "pred = tf.keras.utils.to_categorical(preds,num_classes=10)\n",
        "classificationReport(y_test,pred)\n",
        "multilabel_confusion_matrix(y_test,pred)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.95      0.79      0.86      1814\n",
            "     Class 1       0.90      0.78      0.84      1828\n",
            "     Class 2       0.85      0.86      0.86      1803\n",
            "     Class 3       0.78      0.80      0.79      1719\n",
            "     Class 4       0.72      0.93      0.81      1812\n",
            "     Class 5       0.78      0.86      0.82      1768\n",
            "     Class 6       0.85      0.81      0.83      1832\n",
            "     Class 7       0.90      0.85      0.88      1808\n",
            "     Class 8       0.85      0.79      0.82      1812\n",
            "     Class 9       0.79      0.84      0.82      1804\n",
            "\n",
            "   micro avg       0.83      0.83      0.83     18000\n",
            "   macro avg       0.84      0.83      0.83     18000\n",
            "weighted avg       0.84      0.83      0.83     18000\n",
            " samples avg       0.83      0.83      0.83     18000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[16103,    83],\n",
              "        [  385,  1429]],\n",
              "\n",
              "       [[16023,   149],\n",
              "        [  411,  1417]],\n",
              "\n",
              "       [[15930,   267],\n",
              "        [  244,  1559]],\n",
              "\n",
              "       [[15888,   393],\n",
              "        [  338,  1381]],\n",
              "\n",
              "       [[15551,   637],\n",
              "        [  133,  1679]],\n",
              "\n",
              "       [[15814,   418],\n",
              "        [  254,  1514]],\n",
              "\n",
              "       [[15897,   271],\n",
              "        [  346,  1486]],\n",
              "\n",
              "       [[16019,   173],\n",
              "        [  265,  1543]],\n",
              "\n",
              "       [[15940,   248],\n",
              "        [  377,  1435]],\n",
              "\n",
              "       [[15800,   396],\n",
              "        [  282,  1522]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2DWS0CwEGDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "3c06a489-4672-40e5-9d40-8103181eed43"
      },
      "source": [
        "cm = confusion_matrix(y_test.argmax(axis=1),pred.argmax(axis=1))\n",
        "cm_df = pd.DataFrame(cm,index=[i for i in '0123456789'], columns= [i for i in '0123456789'])\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cm_df,annot=True,cmap='Blues')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5291b17eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_8LcKBUX0rV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As we can see F1-score is also near to one.\n",
        "# class 3 f1-score is under .8.\n",
        "# Over all the model performance is good."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs9C08P3ZtVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}